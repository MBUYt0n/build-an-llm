{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1199344,"sourceType":"datasetVersion","datasetId":683366}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\n\nl = os.listdir(\"/kaggle/input/marvel-cinematic-universe-dialogue-dataset\")\nx = []\nfor i in l:\n        f = open(f\"/kaggle/input/marvel-cinematic-universe-dialogue-dataset/{i}\", \"r\", errors='replace')\n        x.append(f.read())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T18:09:45.574822Z","iopub.execute_input":"2024-07-17T18:09:45.575687Z","iopub.status.idle":"2024-07-17T18:09:45.689253Z","shell.execute_reply.started":"2024-07-17T18:09:45.575654Z","shell.execute_reply":"2024-07-17T18:09:45.688191Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"m = 0\nfor i in x:\n    m = m if len(i) < m else len(i)\nm","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:45.691001Z","iopub.execute_input":"2024-07-17T18:09:45.691317Z","iopub.status.idle":"2024-07-17T18:09:45.699191Z","shell.execute_reply.started":"2024-07-17T18:09:45.691289Z","shell.execute_reply":"2024-07-17T18:09:45.698220Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"68594"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenizing","metadata":{}},{"cell_type":"code","source":"tokens = set(''.join(x))\nvocab_size = len(tokens)\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:45.700618Z","iopub.execute_input":"2024-07-17T18:09:45.701263Z","iopub.status.idle":"2024-07-17T18:09:45.727928Z","shell.execute_reply.started":"2024-07-17T18:09:45.701228Z","shell.execute_reply":"2024-07-17T18:09:45.726951Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"85"},"metadata":{}}]},{"cell_type":"code","source":"tokens = {i:j for i, j in zip(tokens, range(vocab_size))}\ninputs = []\nfor i in x:\n    inputs.append([])\n    for j in i:\n        inputs[-1].append(tokens[j])\nlen(inputs)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:45.729964Z","iopub.execute_input":"2024-07-17T18:09:45.730245Z","iopub.status.idle":"2024-07-17T18:09:46.033055Z","shell.execute_reply.started":"2024-07-17T18:09:45.730223Z","shell.execute_reply":"2024-07-17T18:09:46.032181Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ndel x\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:46.034512Z","iopub.execute_input":"2024-07-17T18:09:46.034804Z","iopub.status.idle":"2024-07-17T18:09:46.082257Z","shell.execute_reply.started":"2024-07-17T18:09:46.034780Z","shell.execute_reply":"2024-07-17T18:09:46.081200Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}]},{"cell_type":"markdown","source":"# Padding","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\ninputs = pad_sequences(inputs, maxlen=m)\n\nprint(inputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:46.084103Z","iopub.execute_input":"2024-07-17T18:09:46.084571Z","iopub.status.idle":"2024-07-17T18:09:57.493556Z","shell.execute_reply.started":"2024-07-17T18:09:46.084536Z","shell.execute_reply":"2024-07-17T18:09:57.492550Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2024-07-17 18:09:47.489638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-17 18:09:47.489744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-17 18:09:47.583301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"(23, 68594)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# LLM setup","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nseq_length = 256\nmax_seq_length = 256\nn_embd = 256","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:57.494614Z","iopub.execute_input":"2024-07-17T18:09:57.495112Z","iopub.status.idle":"2024-07-17T18:09:57.499626Z","shell.execute_reply.started":"2024-07-17T18:09:57.495080Z","shell.execute_reply":"2024-07-17T18:09:57.498735Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Batching\n","metadata":{}},{"cell_type":"code","source":"def create_batches(input_data, batch_size, seq_length):\n    num_samples, total_length = input_data.shape\n    num_chunks = total_length // seq_length + (total_length % seq_length != 0)\n    \n    chunks = []\n    out_chunks = []\n    for i in range(num_samples):\n        for j in range(num_chunks):\n            start_idx = j * seq_length\n            end_idx = min(start_idx + seq_length, total_length)\n            chunk = input_data[i, start_idx:end_idx]\n            \n            out_start_idx = start_idx + 1\n            out_end_idx = min(out_start_idx + seq_length, total_length)\n            out_chunk = input_data[i, out_start_idx:out_end_idx]\n            \n            if end_idx - start_idx < seq_length:\n                padding = torch.zeros(seq_length - (end_idx - start_idx), dtype=chunk.dtype)\n                chunk = torch.cat([chunk, padding])\n                out_padding = torch.zeros(seq_length - (out_end_idx - out_start_idx), dtype=out_chunk.dtype)\n                out_chunk = torch.cat([out_chunk, out_padding])\n            \n            chunks.append(chunk)\n            out_chunks.append(out_chunk)\n    \n    chunks = torch.stack(chunks)\n    num_batches = chunks.size(0) // batch_size\n    batches = torch.split(chunks, batch_size)\n    \n    out_chunks = torch.stack(out_chunks)\n    num_out_batches = out_chunks.size(0) // batch_size\n    out_batches = torch.split(out_chunks, batch_size)\n    \n    return batches, out_batches","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:57.500896Z","iopub.execute_input":"2024-07-17T18:09:57.501262Z","iopub.status.idle":"2024-07-17T18:09:57.514760Z","shell.execute_reply.started":"2024-07-17T18:09:57.501229Z","shell.execute_reply":"2024-07-17T18:09:57.513998Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch \ninputs = torch.tensor(inputs)\ns, o = create_batches(inputs, batch_size, seq_length)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:09:57.517734Z","iopub.execute_input":"2024-07-17T18:09:57.518117Z","iopub.status.idle":"2024-07-17T18:10:01.011349Z","shell.execute_reply.started":"2024-07-17T18:09:57.518093Z","shell.execute_reply":"2024-07-17T18:10:01.010171Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"s[0].dtype","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.012414Z","iopub.execute_input":"2024-07-17T18:10:01.012956Z","iopub.status.idle":"2024-07-17T18:10:01.019056Z","shell.execute_reply.started":"2024-07-17T18:10:01.012929Z","shell.execute_reply":"2024-07-17T18:10:01.018010Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.int32"},"metadata":{}}]},{"cell_type":"code","source":"class Head(torch.nn.Module):\n    def __init__(self, n_embd, head_size, max_seq_length):\n        super().__init__()\n        self.head_size = head_size\n        self.key = torch.nn.Linear(n_embd, self.head_size, bias=False)\n        self.query = torch.nn.Linear(n_embd, self.head_size, bias=False)\n        self.values = torch.nn.Linear(n_embd, self.head_size, bias=False)\n        self.scale_factor = self.head_size ** -0.5\n        self.max_seq_length = max_seq_length\n        \n    def forward(self, q, k, v, mask=None):\n        k = self.key(k)\n        q = self.query(q)\n        v = self.values(v)\n        w = (q @ k.transpose(-2, -1)) * self.scale_factor\n        if mask:\n            device = w.device\n            tril = torch.tril(torch.ones(self.max_seq_length, self.max_seq_length, device=device))\n            seq_length = q.size(1)  # Get the sequence length from q\n            w = w.masked_fill(tril[:seq_length, :seq_length] == 0, float(\"-inf\"))\n        w = torch.nn.functional.softmax(w, dim=-1)\n        return w @ v","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.020252Z","iopub.execute_input":"2024-07-17T18:10:01.020638Z","iopub.status.idle":"2024-07-17T18:10:01.156728Z","shell.execute_reply.started":"2024-07-17T18:10:01.020606Z","shell.execute_reply":"2024-07-17T18:10:01.155827Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class MultiHeadAttention(torch.nn.Module):\n    def __init__(self, num_heads):\n        super().__init__()\n        self.heads = torch.nn.ModuleList([Head(n_embd, n_embd // num_heads, max_seq_length) for i in range(num_heads)])\n        self.out = torch.nn.Linear(n_embd, n_embd)\n        \n    def forward(self, q, k, v, mask=None):\n        head_out = [head(q, k, v, mask) for head in self.heads]\n        concat = torch.cat(head_out, dim=-1)\n        return self.out(concat)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.158000Z","iopub.execute_input":"2024-07-17T18:10:01.158318Z","iopub.status.idle":"2024-07-17T18:10:01.168059Z","shell.execute_reply.started":"2024-07-17T18:10:01.158293Z","shell.execute_reply":"2024-07-17T18:10:01.167092Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class FF(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = torch.nn.Linear(n_embd, 4 * n_embd)\n        self.linear2 = torch.nn.Linear(4 * n_embd, n_embd)\n        \n    def forward(self, x):\n        return self.linear2(torch.nn.functional.relu(self.linear1(x)))        ","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.169208Z","iopub.execute_input":"2024-07-17T18:10:01.169495Z","iopub.status.idle":"2024-07-17T18:10:01.175979Z","shell.execute_reply.started":"2024-07-17T18:10:01.169455Z","shell.execute_reply":"2024-07-17T18:10:01.175074Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Encode(torch.nn.Module):\n    def __init__(self, num_heads):\n        super().__init__()\n        self.ff = FF()\n        self.attn = MultiHeadAttention(num_heads)\n        self.l1 = torch.nn.LayerNorm(n_embd)\n        self.l2 = torch.nn.LayerNorm(n_embd)\n        self.dropout1 = torch.nn.Dropout(0.1)\n        self.dropout2 = torch.nn.Dropout(0.1)\n        \n    def forward(self, x):\n        attn_out = self.attn(x, x, x)\n        x = self.l1(self.dropout1(attn_out) + x)\n        ff_out = self.ff(x)\n        attn_out = self.attn(x, x, x)\n        return self.l2(self.dropout2(attn_out) + x)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.177122Z","iopub.execute_input":"2024-07-17T18:10:01.177380Z","iopub.status.idle":"2024-07-17T18:10:01.185693Z","shell.execute_reply.started":"2024-07-17T18:10:01.177358Z","shell.execute_reply":"2024-07-17T18:10:01.184716Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class Encoder(torch.nn.Module):\n    def __init__(self, vocab_size, max_seq_length, num_heads, num_layers, n_embd):\n        super().__init__()\n        self.embedding = torch.nn.Embedding(vocab_size, n_embd)\n        self.pos_embedding = torch.nn.Embedding(max_seq_length, n_embd)\n        self.layers = torch.nn.ModuleList([Encode(num_heads) for i in range(num_layers)])\n        self.norm = torch.nn.LayerNorm(n_embd)\n    \n\n    def forward(self, x):\n        seq_length = x.shape[1]  \n        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0).expand_as(x)          \n        x = self.embedding(x) + self.pos_embedding(positions)  \n        for layer in self.layers:  \n            x = layer(x)\n        return self.norm(x) ","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:10:01.186835Z","iopub.execute_input":"2024-07-17T18:10:01.187106Z","iopub.status.idle":"2024-07-17T18:10:01.196519Z","shell.execute_reply.started":"2024-07-17T18:10:01.187083Z","shell.execute_reply":"2024-07-17T18:10:01.195607Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Decode(torch.nn.Module):\n    def __init__(self, num_heads, n_embd):\n        super().__init__()\n        self.attn1 = MultiHeadAttention(num_heads)\n        self.attn2 = MultiHeadAttention(num_heads)\n        self.norm1 = torch.nn.LayerNorm(n_embd)\n        self.norm2 = torch.nn.LayerNorm(n_embd)\n        self.norm3 = torch.nn.LayerNorm(n_embd)\n        self.ff = FF()\n    \n    def forward(self, x, enc):\n        attn_out = self.attn1(x, x, x, 1)\n        x = self.norm1(x + attn_out)\n        attn_out = self.attn2(x, enc, enc, 1)\n        x =  self.norm2(x + attn_out)\n        return self.norm3(x + self.ff(x))","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:06.332294Z","iopub.execute_input":"2024-07-17T18:14:06.332945Z","iopub.status.idle":"2024-07-17T18:14:06.340330Z","shell.execute_reply.started":"2024-07-17T18:14:06.332912Z","shell.execute_reply":"2024-07-17T18:14:06.339356Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class Decoder(torch.nn.Module):\n    def __init__(self, vocab_size, max_seq_len, num_layers, num_heads, n_embd, hidden_dim):\n        super().__init__()\n        self.embedding = torch.nn.Embedding(vocab_size, n_embd)\n        self.pos_embedding = torch.nn.Embedding(max_seq_len, n_embd)\n        self.lstm = torch.nn.LSTM(n_embd, hidden_dim, batch_first=True)  # Initialize LSTM\n        self.layers = torch.nn.ModuleList([Decode(num_heads, n_embd) for i in range(num_layers)])\n        self.norm = torch.nn.LayerNorm(n_embd)\n        \n    def forward(self, x, enc_output):\n        seq_length = x.size(1)\n        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0).expand_as(x)         \n        x = self.embedding(x) + self.pos_embedding(positions)\n        x, _ = self.lstm(x)  # Pass through LSTM\n        for layer in self.layers:\n            x = layer(x, enc_output)\n        return self.norm(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:08.012316Z","iopub.execute_input":"2024-07-17T18:14:08.013323Z","iopub.status.idle":"2024-07-17T18:14:08.022051Z","shell.execute_reply.started":"2024-07-17T18:14:08.013288Z","shell.execute_reply":"2024-07-17T18:14:08.021080Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass llm(torch.nn.Module):\n    def __init__(self, vocab_size, max_seq_length, num_heads, num_layers, n_embd):\n        super().__init__()\n        self.enc = Encoder(vocab_size, max_seq_length, num_heads, num_layers, n_embd)\n        self.dec = Decoder(vocab_size, max_seq_length, num_heads, num_layers, n_embd, hidden_dim=n_embd)\n        self.out = torch.nn.Linear(n_embd, vocab_size)\n        self.max_seq_length = max_seq_length\n        self.vocab_size = vocab_size\n        \n    def forward(self, x, y=None, enc_out=None):\n        if enc_out is None:\n            enc_out = self.enc(x)\n        if y is not None:\n            dec_out = self.dec(y, enc_out)\n            return self.out(dec_out)\n        return enc_out\n\n    def generate(self, input_ids, max_length=50):\n        self.eval()\n        with torch.no_grad():\n            enc_out = self.forward(input_ids)  # Get encoder output once for the input\n            generated = input_ids\n            for _ in range(max_length):\n                # Assuming input_ids is a batch with size [1, seq_len]\n                output = self.forward(input_ids, generated, enc_out=enc_out)  # Use cached encoder output\n                next_token_logits = output[:, -1, :]\n                next_token_id = next_token_logits.argmax(dim=-1).unsqueeze(-1)\n                generated = torch.cat([generated, next_token_id], dim=-1)\n        return generated","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:09.091054Z","iopub.execute_input":"2024-07-17T18:14:09.091706Z","iopub.status.idle":"2024-07-17T18:14:09.101688Z","shell.execute_reply.started":"2024-07-17T18:14:09.091671Z","shell.execute_reply":"2024-07-17T18:14:09.100655Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\")\nmodel = llm(vocab_size,  max_seq_length=max_seq_length, num_heads=4, num_layers=2, n_embd=n_embd).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:09.999705Z","iopub.execute_input":"2024-07-17T18:14:10.000443Z","iopub.status.idle":"2024-07-17T18:14:10.440867Z","shell.execute_reply.started":"2024-07-17T18:14:10.000400Z","shell.execute_reply":"2024-07-17T18:14:10.439989Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model(s[0].to(device), o[0].to(device)).shape","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:12.613760Z","iopub.execute_input":"2024-07-17T18:14:12.614183Z","iopub.status.idle":"2024-07-17T18:14:12.990846Z","shell.execute_reply.started":"2024-07-17T18:14:12.614152Z","shell.execute_reply":"2024-07-17T18:14:12.989836Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([16, 256, 85])"},"metadata":{}}]},{"cell_type":"code","source":"lossFn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:14:16.490262Z","iopub.execute_input":"2024-07-17T18:14:16.490971Z","iopub.status.idle":"2024-07-17T18:14:17.575742Z","shell.execute_reply.started":"2024-07-17T18:14:16.490937Z","shell.execute_reply":"2024-07-17T18:14:17.574946Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.tensorboard import SummaryWriter\nimport gc\n\n# Initialize SummaryWriter\nwriter = SummaryWriter()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Number of epochs\nnum_epochs = 3\n\nscaler = torch.cuda.amp.GradScaler()\n\nfor epoch in range(num_epochs):\n    for i, (a, b) in enumerate(zip(s, o)):\n        a = a.to(device)\n        b = b.to(device)\n\n        with torch.cuda.amp.autocast():\n            logits = model(a, b)\n            loss = lossFn(logits.view(-1, model.vocab_size), b.view(-1).long())\n\n        # Zero gradients\n        optimizer.zero_grad()\n\n        scaler.scale(loss).backward()\n\n        scaler.step(optimizer)\n        scaler.update()\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}], Loss: {loss.item()}\")\n\n        # Log the loss\n        writer.add_scalar('Loss/train', loss.item(), epoch * len(inputs) + i)\n    \n        a = a.cpu()\n        b = b.cpu()\n        logits = logits.cpu()\n        loss = loss.cpu()\n        del a, b, logits, loss\n        torch.cuda.empty_cache()\n        gc.collect()\n\n# Close the SummaryWriter\nwriter.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context = torch.zeros((8, 256), dtype=torch.long, device=device)\na = model.generate(context, max_length=500)[0].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T18:23:51.577576Z","iopub.execute_input":"2024-07-17T18:23:51.577961Z","iopub.status.idle":"2024-07-17T18:23:51.623234Z","shell.execute_reply.started":"2024-07-17T18:23:51.577930Z","shell.execute_reply":"2024-07-17T18:23:51.622164Z"},"trusted":true},"execution_count":36,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(context, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}