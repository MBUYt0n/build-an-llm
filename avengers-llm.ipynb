{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d747af6b",
   "metadata": {
    "papermill": {
     "duration": 0.008396,
     "end_time": "2024-07-18T01:50:12.588202",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.579806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d74b70",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:12.605069Z",
     "iopub.status.busy": "2024-07-18T01:50:12.604796Z",
     "iopub.status.idle": "2024-07-18T01:50:12.724341Z",
     "shell.execute_reply": "2024-07-18T01:50:12.723565Z"
    },
    "papermill": {
     "duration": 0.130144,
     "end_time": "2024-07-18T01:50:12.726301",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.596157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "l = os.listdir(\"/kaggle/input/marvel-cinematic-universe-dialogue-dataset\")\n",
    "x = []\n",
    "for i in l:\n",
    "        f = open(f\"/kaggle/input/marvel-cinematic-universe-dialogue-dataset/{i}\", \"r\", errors='replace')\n",
    "        x.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec49d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:12.743832Z",
     "iopub.status.busy": "2024-07-18T01:50:12.743227Z",
     "iopub.status.idle": "2024-07-18T01:50:12.749877Z",
     "shell.execute_reply": "2024-07-18T01:50:12.749027Z"
    },
    "papermill": {
     "duration": 0.017378,
     "end_time": "2024-07-18T01:50:12.751863",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.734485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68594"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 0\n",
    "for i in x:\n",
    "    m = m if len(i) < m else len(i)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a203400",
   "metadata": {
    "papermill": {
     "duration": 0.007892,
     "end_time": "2024-07-18T01:50:12.767686",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.759794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872699c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:12.785483Z",
     "iopub.status.busy": "2024-07-18T01:50:12.784808Z",
     "iopub.status.idle": "2024-07-18T01:50:12.809022Z",
     "shell.execute_reply": "2024-07-18T01:50:12.808223Z"
    },
    "papermill": {
     "duration": 0.035158,
     "end_time": "2024-07-18T01:50:12.810830",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.775672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = set(''.join(x))\n",
    "vocab_size = len(tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07000b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:12.827907Z",
     "iopub.status.busy": "2024-07-18T01:50:12.827639Z",
     "iopub.status.idle": "2024-07-18T01:50:13.138350Z",
     "shell.execute_reply": "2024-07-18T01:50:13.137540Z"
    },
    "papermill": {
     "duration": 0.321561,
     "end_time": "2024-07-18T01:50:13.140397",
     "exception": false,
     "start_time": "2024-07-18T01:50:12.818836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = {i:j for i, j in zip(tokens, range(vocab_size))}\n",
    "inputs = []\n",
    "for i in x:\n",
    "    inputs.append([])\n",
    "    for j in i:\n",
    "        inputs[-1].append(tokens[j])\n",
    "len(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb5b6f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:13.158917Z",
     "iopub.status.busy": "2024-07-18T01:50:13.158363Z",
     "iopub.status.idle": "2024-07-18T01:50:13.198328Z",
     "shell.execute_reply": "2024-07-18T01:50:13.197509Z"
    },
    "papermill": {
     "duration": 0.051703,
     "end_time": "2024-07-18T01:50:13.200308",
     "exception": false,
     "start_time": "2024-07-18T01:50:13.148605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173072e",
   "metadata": {
    "papermill": {
     "duration": 0.008243,
     "end_time": "2024-07-18T01:50:13.216937",
     "exception": false,
     "start_time": "2024-07-18T01:50:13.208694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d81b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:13.235217Z",
     "iopub.status.busy": "2024-07-18T01:50:13.234592Z",
     "iopub.status.idle": "2024-07-18T01:50:24.800934Z",
     "shell.execute_reply": "2024-07-18T01:50:24.799933Z"
    },
    "papermill": {
     "duration": 11.577831,
     "end_time": "2024-07-18T01:50:24.803062",
     "exception": false,
     "start_time": "2024-07-18T01:50:13.225231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 01:50:14.762115: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 01:50:14.762203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 01:50:14.866169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 68594)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "inputs = pad_sequences(inputs, maxlen=m)\n",
    "\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a0bc7",
   "metadata": {
    "papermill": {
     "duration": 0.008271,
     "end_time": "2024-07-18T01:50:24.820132",
     "exception": false,
     "start_time": "2024-07-18T01:50:24.811861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LLM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09ddfc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:24.838456Z",
     "iopub.status.busy": "2024-07-18T01:50:24.837950Z",
     "iopub.status.idle": "2024-07-18T01:50:24.842101Z",
     "shell.execute_reply": "2024-07-18T01:50:24.841303Z"
    },
    "papermill": {
     "duration": 0.015488,
     "end_time": "2024-07-18T01:50:24.844028",
     "exception": false,
     "start_time": "2024-07-18T01:50:24.828540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_length = 256\n",
    "max_seq_length = 256\n",
    "n_embd = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf5e14",
   "metadata": {
    "papermill": {
     "duration": 0.008233,
     "end_time": "2024-07-18T01:50:24.860731",
     "exception": false,
     "start_time": "2024-07-18T01:50:24.852498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Batching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb3f976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:24.879012Z",
     "iopub.status.busy": "2024-07-18T01:50:24.878755Z",
     "iopub.status.idle": "2024-07-18T01:50:24.888329Z",
     "shell.execute_reply": "2024-07-18T01:50:24.887432Z"
    },
    "papermill": {
     "duration": 0.020714,
     "end_time": "2024-07-18T01:50:24.890145",
     "exception": false,
     "start_time": "2024-07-18T01:50:24.869431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_batches(input_data, batch_size, seq_length):\n",
    "    num_samples, total_length = input_data.shape\n",
    "    num_chunks = total_length // seq_length + (total_length % seq_length != 0)\n",
    "    \n",
    "    chunks = []\n",
    "    out_chunks = []\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_chunks):\n",
    "            start_idx = j * seq_length\n",
    "            end_idx = min(start_idx + seq_length, total_length)\n",
    "            chunk = input_data[i, start_idx:end_idx]\n",
    "            \n",
    "            out_start_idx = start_idx + 1\n",
    "            out_end_idx = min(out_start_idx + seq_length, total_length)\n",
    "            out_chunk = input_data[i, out_start_idx:out_end_idx]\n",
    "            \n",
    "            if end_idx - start_idx < seq_length:\n",
    "                padding = torch.zeros(seq_length - (end_idx - start_idx), dtype=chunk.dtype)\n",
    "                chunk = torch.cat([chunk, padding])\n",
    "                out_padding = torch.zeros(seq_length - (out_end_idx - out_start_idx), dtype=out_chunk.dtype)\n",
    "                out_chunk = torch.cat([out_chunk, out_padding])\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "            out_chunks.append(out_chunk)\n",
    "    \n",
    "    chunks = torch.stack(chunks)\n",
    "    num_batches = chunks.size(0) // batch_size\n",
    "    batches = torch.split(chunks, batch_size)\n",
    "    \n",
    "    out_chunks = torch.stack(out_chunks)\n",
    "    num_out_batches = out_chunks.size(0) // batch_size\n",
    "    out_batches = torch.split(out_chunks, batch_size)\n",
    "    \n",
    "    return batches, out_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a2b1f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:24.908048Z",
     "iopub.status.busy": "2024-07-18T01:50:24.907769Z",
     "iopub.status.idle": "2024-07-18T01:50:28.505394Z",
     "shell.execute_reply": "2024-07-18T01:50:28.504580Z"
    },
    "papermill": {
     "duration": 3.609245,
     "end_time": "2024-07-18T01:50:28.507765",
     "exception": false,
     "start_time": "2024-07-18T01:50:24.898520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "inputs = torch.tensor(inputs)\n",
    "s, o = create_batches(inputs, batch_size, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be720505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.526940Z",
     "iopub.status.busy": "2024-07-18T01:50:28.526014Z",
     "iopub.status.idle": "2024-07-18T01:50:28.532198Z",
     "shell.execute_reply": "2024-07-18T01:50:28.531329Z"
    },
    "papermill": {
     "duration": 0.017393,
     "end_time": "2024-07-18T01:50:28.534065",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.516672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b21842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.552782Z",
     "iopub.status.busy": "2024-07-18T01:50:28.552247Z",
     "iopub.status.idle": "2024-07-18T01:50:28.561198Z",
     "shell.execute_reply": "2024-07-18T01:50:28.560392Z"
    },
    "papermill": {
     "duration": 0.020134,
     "end_time": "2024-07-18T01:50:28.563068",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.542934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, n_embd, head_size, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.key = torch.nn.Linear(n_embd, self.head_size, bias=False)\n",
    "        self.query = torch.nn.Linear(n_embd, self.head_size, bias=False)\n",
    "        self.values = torch.nn.Linear(n_embd, self.head_size, bias=False)\n",
    "        self.scale_factor = self.head_size ** -0.5\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k = self.key(k)\n",
    "        q = self.query(q)\n",
    "        v = self.values(v)\n",
    "        w = (q @ k.transpose(-2, -1)) * self.scale_factor\n",
    "        if mask:\n",
    "            device = w.device\n",
    "            tril = torch.tril(torch.ones(self.max_seq_length, self.max_seq_length, device=device))\n",
    "            seq_length = q.size(1)  # Get the sequence length from q\n",
    "            w = w.masked_fill(tril[:seq_length, :seq_length] == 0, float(\"-inf\"))\n",
    "        w = torch.nn.functional.softmax(w, dim=-1)\n",
    "        return w @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474d6ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.581240Z",
     "iopub.status.busy": "2024-07-18T01:50:28.580979Z",
     "iopub.status.idle": "2024-07-18T01:50:28.587134Z",
     "shell.execute_reply": "2024-07-18T01:50:28.586324Z"
    },
    "papermill": {
     "duration": 0.017346,
     "end_time": "2024-07-18T01:50:28.588994",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.571648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = torch.nn.ModuleList([Head(n_embd, n_embd // num_heads, max_seq_length) for i in range(num_heads)])\n",
    "        self.out = torch.nn.Linear(n_embd, n_embd)\n",
    "        \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        head_out = [head(q, k, v, mask) for head in self.heads]\n",
    "        concat = torch.cat(head_out, dim=-1)\n",
    "        return self.out(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74d8e4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.606996Z",
     "iopub.status.busy": "2024-07-18T01:50:28.606749Z",
     "iopub.status.idle": "2024-07-18T01:50:28.612035Z",
     "shell.execute_reply": "2024-07-18T01:50:28.611228Z"
    },
    "papermill": {
     "duration": 0.016372,
     "end_time": "2024-07-18T01:50:28.613872",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.597500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = torch.nn.Linear(n_embd, 4 * n_embd)\n",
    "        self.linear2 = torch.nn.Linear(4 * n_embd, n_embd)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear2(torch.nn.functional.relu(self.linear1(x)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6669ad72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.632121Z",
     "iopub.status.busy": "2024-07-18T01:50:28.631870Z",
     "iopub.status.idle": "2024-07-18T01:50:28.638581Z",
     "shell.execute_reply": "2024-07-18T01:50:28.637724Z"
    },
    "papermill": {
     "duration": 0.017989,
     "end_time": "2024-07-18T01:50:28.640465",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.622476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encode(torch.nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        self.ff = FF()\n",
    "        self.attn = MultiHeadAttention(num_heads)\n",
    "        self.l1 = torch.nn.LayerNorm(n_embd)\n",
    "        self.l2 = torch.nn.LayerNorm(n_embd)\n",
    "        self.dropout1 = torch.nn.Dropout(0.1)\n",
    "        self.dropout2 = torch.nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_out = self.attn(x, x, x)\n",
    "        x = self.l1(self.dropout1(attn_out) + x)\n",
    "        ff_out = self.ff(x)\n",
    "        attn_out = self.attn(x, x, x)\n",
    "        return self.l2(self.dropout2(attn_out) + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa856a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.658750Z",
     "iopub.status.busy": "2024-07-18T01:50:28.658481Z",
     "iopub.status.idle": "2024-07-18T01:50:28.665580Z",
     "shell.execute_reply": "2024-07-18T01:50:28.664731Z"
    },
    "papermill": {
     "duration": 0.018373,
     "end_time": "2024-07-18T01:50:28.667461",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.649088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_length, num_heads, num_layers, n_embd):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_embedding = torch.nn.Embedding(max_seq_length, n_embd)\n",
    "        self.layers = torch.nn.ModuleList([Encode(num_heads) for i in range(num_layers)])\n",
    "        self.norm = torch.nn.LayerNorm(n_embd)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.shape[1]  \n",
    "        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0).expand_as(x)          \n",
    "        x = self.embedding(x) + self.pos_embedding(positions)  \n",
    "        for layer in self.layers:  \n",
    "            x = layer(x)\n",
    "        return self.norm(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0a3a91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.685698Z",
     "iopub.status.busy": "2024-07-18T01:50:28.685432Z",
     "iopub.status.idle": "2024-07-18T01:50:28.692105Z",
     "shell.execute_reply": "2024-07-18T01:50:28.691232Z"
    },
    "papermill": {
     "duration": 0.017754,
     "end_time": "2024-07-18T01:50:28.693992",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.676238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decode(torch.nn.Module):\n",
    "    def __init__(self, num_heads, n_embd):\n",
    "        super().__init__()\n",
    "        self.attn1 = MultiHeadAttention(num_heads)\n",
    "        self.attn2 = MultiHeadAttention(num_heads)\n",
    "        self.norm1 = torch.nn.LayerNorm(n_embd)\n",
    "        self.norm2 = torch.nn.LayerNorm(n_embd)\n",
    "        self.norm3 = torch.nn.LayerNorm(n_embd)\n",
    "        self.ff = FF()\n",
    "    \n",
    "    def forward(self, x, enc):\n",
    "        attn_out = self.attn1(x, x, x, 1)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        attn_out = self.attn2(x, enc, enc, 1)\n",
    "        x =  self.norm2(x + attn_out)\n",
    "        return self.norm3(x + self.ff(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8646f37d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.712205Z",
     "iopub.status.busy": "2024-07-18T01:50:28.711934Z",
     "iopub.status.idle": "2024-07-18T01:50:28.719921Z",
     "shell.execute_reply": "2024-07-18T01:50:28.719032Z"
    },
    "papermill": {
     "duration": 0.019168,
     "end_time": "2024-07-18T01:50:28.721788",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.702620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, num_layers, num_heads, n_embd, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_embedding = torch.nn.Embedding(max_seq_len, n_embd)\n",
    "        self.lstm = torch.nn.LSTM(n_embd, hidden_dim, batch_first=True)  # Initialize LSTM\n",
    "        self.layers = torch.nn.ModuleList([Decode(num_heads, n_embd) for i in range(num_layers)])\n",
    "        self.norm = torch.nn.LayerNorm(n_embd)\n",
    "        \n",
    "    def forward(self, x, enc_output):\n",
    "        seq_length = x.size(1)\n",
    "        positions = torch.arange(0, seq_length, device=x.device).unsqueeze(0).expand_as(x)         \n",
    "        x = self.embedding(x) + self.pos_embedding(positions)\n",
    "        x, _ = self.lstm(x) \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9402c97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.740401Z",
     "iopub.status.busy": "2024-07-18T01:50:28.740117Z",
     "iopub.status.idle": "2024-07-18T01:50:28.749680Z",
     "shell.execute_reply": "2024-07-18T01:50:28.748844Z"
    },
    "papermill": {
     "duration": 0.021047,
     "end_time": "2024-07-18T01:50:28.751497",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.730450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class llm(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_length, num_heads, num_layers, n_embd):\n",
    "        super().__init__()\n",
    "        self.enc = Encoder(vocab_size, max_seq_length, num_heads, num_layers, n_embd)\n",
    "        self.dec = Decoder(vocab_size, max_seq_length, num_heads, num_layers, n_embd, hidden_dim=n_embd)\n",
    "        self.out = torch.nn.Linear(n_embd, vocab_size)\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self, x, y=None, enc_out=None):\n",
    "        if enc_out is None:\n",
    "            enc_out = self.enc(x)\n",
    "        if y is not None:\n",
    "            dec_out = self.dec(y, enc_out)\n",
    "            return self.out(dec_out)\n",
    "        return enc_out\n",
    "\n",
    "    def generate(self, input_ids, max_length=50):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            enc_out = self.forward(input_ids)  # Assuming this runs the encoder and returns the output\n",
    "            generated = input_ids\n",
    "\n",
    "            for _ in range(max_length):\n",
    "                output = self.forward(input_ids, generated, enc_out=enc_out)\n",
    "                next_token_logits = output[:, -1, :]\n",
    "                next_token_probs = torch.nn.functional.softmax(next_token_logits, dim=-1)\n",
    "                next_token_id = next_token_probs.argmax(dim=-1).unsqueeze(-1)\n",
    "                generated = torch.cat([generated[:, 1:], next_token_id], dim=-1)\n",
    "        return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9eb92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:28.769949Z",
     "iopub.status.busy": "2024-07-18T01:50:28.769689Z",
     "iopub.status.idle": "2024-07-18T01:50:29.227888Z",
     "shell.execute_reply": "2024-07-18T01:50:29.226837Z"
    },
    "papermill": {
     "duration": 0.470007,
     "end_time": "2024-07-18T01:50:29.230186",
     "exception": false,
     "start_time": "2024-07-18T01:50:28.760179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = llm(vocab_size,  max_seq_length=max_seq_length, num_heads=4, num_layers=2, n_embd=n_embd).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66ae174d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:29.249114Z",
     "iopub.status.busy": "2024-07-18T01:50:29.248595Z",
     "iopub.status.idle": "2024-07-18T01:50:30.640188Z",
     "shell.execute_reply": "2024-07-18T01:50:30.638962Z"
    },
    "papermill": {
     "duration": 1.404012,
     "end_time": "2024-07-18T01:50:30.643096",
     "exception": false,
     "start_time": "2024-07-18T01:50:29.239084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.generate(s[0].to(device))\n",
    "detok = {tokens[i]:i for i in tokens}\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cfbf5f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:30.662554Z",
     "iopub.status.busy": "2024-07-18T01:50:30.662217Z",
     "iopub.status.idle": "2024-07-18T01:50:30.681510Z",
     "shell.execute_reply": "2024-07-18T01:50:30.680639Z"
    },
    "papermill": {
     "duration": 0.030738,
     "end_time": "2024-07-18T01:50:30.683322",
     "exception": false,
     "start_time": "2024-07-18T01:50:30.652584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8                                                                                                                                                                                                              nOO7n8,OOOt87'7n8,OOOt87'7n8,OOOt87'7n8,OOOO7'7nO8\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.to(\"cpu\")\n",
    "q = \"\"\n",
    "for i in a:\n",
    "    for j in i:\n",
    "        q += detok[int(j)]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a8aab20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:30.702051Z",
     "iopub.status.busy": "2024-07-18T01:50:30.701801Z",
     "iopub.status.idle": "2024-07-18T01:50:31.754590Z",
     "shell.execute_reply": "2024-07-18T01:50:31.753827Z"
    },
    "papermill": {
     "duration": 1.064464,
     "end_time": "2024-07-18T01:50:31.756685",
     "exception": false,
     "start_time": "2024-07-18T01:50:30.692221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lossFn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d400da22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:50:31.776484Z",
     "iopub.status.busy": "2024-07-18T01:50:31.776184Z",
     "iopub.status.idle": "2024-07-18T01:56:39.932544Z",
     "shell.execute_reply": "2024-07-18T01:56:39.931611Z"
    },
    "papermill": {
     "duration": 368.168671,
     "end_time": "2024-07-18T01:56:39.934684",
     "exception": false,
     "start_time": "2024-07-18T01:50:31.766013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [1], Loss: 4.553524971008301\n",
      "Epoch [1/3], Batch [2], Loss: 4.551568031311035\n",
      "Epoch [1/3], Batch [3], Loss: 4.479615688323975\n",
      "Epoch [1/3], Batch [4], Loss: 4.0705037117004395\n",
      "Epoch [1/3], Batch [5], Loss: 3.7538328170776367\n",
      "Epoch [1/3], Batch [6], Loss: 3.4531984329223633\n",
      "Epoch [1/3], Batch [7], Loss: 3.3464865684509277\n",
      "Epoch [1/3], Batch [8], Loss: 3.273164749145508\n",
      "Epoch [1/3], Batch [9], Loss: 3.0045199394226074\n",
      "Epoch [1/3], Batch [10], Loss: 3.084186553955078\n",
      "Epoch [1/3], Batch [11], Loss: 2.8182950019836426\n",
      "Epoch [1/3], Batch [12], Loss: 2.692470073699951\n",
      "Epoch [1/3], Batch [13], Loss: 2.6794252395629883\n",
      "Epoch [1/3], Batch [14], Loss: 2.6621251106262207\n",
      "Epoch [1/3], Batch [15], Loss: 2.3964428901672363\n",
      "Epoch [1/3], Batch [16], Loss: 2.4877424240112305\n",
      "Epoch [1/3], Batch [17], Loss: 1.7258765697479248\n",
      "Epoch [1/3], Batch [18], Loss: 0.14542877674102783\n",
      "Epoch [1/3], Batch [19], Loss: 0.09732142090797424\n",
      "Epoch [1/3], Batch [20], Loss: 0.0641212984919548\n",
      "Epoch [1/3], Batch [21], Loss: 0.044279783964157104\n",
      "Epoch [1/3], Batch [22], Loss: 0.98785799741745\n",
      "Epoch [1/3], Batch [23], Loss: 1.6772148609161377\n",
      "Epoch [1/3], Batch [24], Loss: 1.6297836303710938\n",
      "Epoch [1/3], Batch [25], Loss: 1.5195621252059937\n",
      "Epoch [1/3], Batch [26], Loss: 1.4489496946334839\n",
      "Epoch [1/3], Batch [27], Loss: 1.3437209129333496\n",
      "Epoch [1/3], Batch [28], Loss: 1.3524318933486938\n",
      "Epoch [1/3], Batch [29], Loss: 1.311387538909912\n",
      "Epoch [1/3], Batch [30], Loss: 1.1860555410385132\n",
      "Epoch [1/3], Batch [31], Loss: 1.137691617012024\n",
      "Epoch [1/3], Batch [32], Loss: 1.085756778717041\n",
      "Epoch [1/3], Batch [33], Loss: 0.997018039226532\n",
      "Epoch [1/3], Batch [34], Loss: 0.5184727311134338\n",
      "Epoch [1/3], Batch [35], Loss: 0.01698293350636959\n",
      "Epoch [1/3], Batch [36], Loss: 0.47579753398895264\n",
      "Epoch [1/3], Batch [37], Loss: 0.8918108344078064\n",
      "Epoch [1/3], Batch [38], Loss: 0.8896752595901489\n",
      "Epoch [1/3], Batch [39], Loss: 0.8145614862442017\n",
      "Epoch [1/3], Batch [40], Loss: 0.7847750782966614\n",
      "Epoch [1/3], Batch [41], Loss: 0.8039782643318176\n",
      "Epoch [1/3], Batch [42], Loss: 0.669873058795929\n",
      "Epoch [1/3], Batch [43], Loss: 0.742919385433197\n",
      "Epoch [1/3], Batch [44], Loss: 0.6956778764724731\n",
      "Epoch [1/3], Batch [45], Loss: 0.6683417558670044\n",
      "Epoch [1/3], Batch [46], Loss: 0.5931152701377869\n",
      "Epoch [1/3], Batch [47], Loss: 0.590472936630249\n",
      "Epoch [1/3], Batch [48], Loss: 0.5821681618690491\n",
      "Epoch [1/3], Batch [49], Loss: 0.5890307426452637\n",
      "Epoch [1/3], Batch [50], Loss: 0.4766739308834076\n",
      "Epoch [1/3], Batch [51], Loss: 0.12643803656101227\n",
      "Epoch [1/3], Batch [52], Loss: 0.42381322383880615\n",
      "Epoch [1/3], Batch [53], Loss: 0.7905171513557434\n",
      "Epoch [1/3], Batch [54], Loss: 0.5225988030433655\n",
      "Epoch [1/3], Batch [55], Loss: 0.6363973021507263\n",
      "Epoch [1/3], Batch [56], Loss: 0.7298305630683899\n",
      "Epoch [1/3], Batch [57], Loss: 0.4368517994880676\n",
      "Epoch [1/3], Batch [58], Loss: 0.5607399940490723\n",
      "Epoch [1/3], Batch [59], Loss: 1.1062819957733154\n",
      "Epoch [1/3], Batch [60], Loss: 0.4978986382484436\n",
      "Epoch [1/3], Batch [61], Loss: 0.342861533164978\n",
      "Epoch [1/3], Batch [62], Loss: 0.4937860667705536\n",
      "Epoch [1/3], Batch [63], Loss: 0.4822932779788971\n",
      "Epoch [1/3], Batch [64], Loss: 0.4810854196548462\n",
      "Epoch [1/3], Batch [65], Loss: 0.6540668606758118\n",
      "Epoch [1/3], Batch [66], Loss: 0.4943302571773529\n",
      "Epoch [1/3], Batch [67], Loss: 0.44409802556037903\n",
      "Epoch [1/3], Batch [68], Loss: 0.01302110031247139\n",
      "Epoch [1/3], Batch [69], Loss: 0.012767290696501732\n",
      "Epoch [1/3], Batch [70], Loss: 0.012338528409600258\n",
      "Epoch [1/3], Batch [71], Loss: 0.01181533932685852\n",
      "Epoch [1/3], Batch [72], Loss: 0.011216618120670319\n",
      "Epoch [1/3], Batch [73], Loss: 0.010609855875372887\n",
      "Epoch [1/3], Batch [74], Loss: 0.15837469696998596\n",
      "Epoch [1/3], Batch [75], Loss: 0.24763162434101105\n",
      "Epoch [1/3], Batch [76], Loss: 0.253235787153244\n",
      "Epoch [1/3], Batch [77], Loss: 0.22642797231674194\n",
      "Epoch [1/3], Batch [78], Loss: 0.25397729873657227\n",
      "Epoch [1/3], Batch [79], Loss: 0.2043440043926239\n",
      "Epoch [1/3], Batch [80], Loss: 0.18719016015529633\n",
      "Epoch [1/3], Batch [81], Loss: 0.22770389914512634\n",
      "Epoch [1/3], Batch [82], Loss: 0.17551599442958832\n",
      "Epoch [1/3], Batch [83], Loss: 0.2292724847793579\n",
      "Epoch [1/3], Batch [84], Loss: 0.15461879968643188\n",
      "Epoch [1/3], Batch [85], Loss: 0.007091076113283634\n",
      "Epoch [1/3], Batch [86], Loss: 0.006998658180236816\n",
      "Epoch [1/3], Batch [87], Loss: 0.006901507265865803\n",
      "Epoch [1/3], Batch [88], Loss: 0.006804295815527439\n",
      "Epoch [1/3], Batch [89], Loss: 0.026667878031730652\n",
      "Epoch [1/3], Batch [90], Loss: 0.20529191195964813\n",
      "Epoch [1/3], Batch [91], Loss: 0.1885286271572113\n",
      "Epoch [1/3], Batch [92], Loss: 0.1813933253288269\n",
      "Epoch [1/3], Batch [93], Loss: 0.22706499695777893\n",
      "Epoch [1/3], Batch [94], Loss: 0.1751827895641327\n",
      "Epoch [1/3], Batch [95], Loss: 0.16575974225997925\n",
      "Epoch [1/3], Batch [96], Loss: 0.2044249176979065\n",
      "Epoch [1/3], Batch [97], Loss: 0.17608731985092163\n",
      "Epoch [1/3], Batch [98], Loss: 0.15913063287734985\n",
      "Epoch [1/3], Batch [99], Loss: 0.15496334433555603\n",
      "Epoch [1/3], Batch [100], Loss: 0.16951318085193634\n",
      "Epoch [1/3], Batch [101], Loss: 0.0636930763721466\n",
      "Epoch [1/3], Batch [102], Loss: 0.006050357595086098\n",
      "Epoch [1/3], Batch [103], Loss: 0.006019674241542816\n",
      "Epoch [1/3], Batch [104], Loss: 0.005980553105473518\n",
      "Epoch [1/3], Batch [105], Loss: 0.11550258845090866\n",
      "Epoch [1/3], Batch [106], Loss: 0.1191689670085907\n",
      "Epoch [1/3], Batch [107], Loss: 0.13968241214752197\n",
      "Epoch [1/3], Batch [108], Loss: 0.11617092788219452\n",
      "Epoch [1/3], Batch [109], Loss: 0.12310443818569183\n",
      "Epoch [1/3], Batch [110], Loss: 0.1307474970817566\n",
      "Epoch [1/3], Batch [111], Loss: 0.12643136084079742\n",
      "Epoch [1/3], Batch [112], Loss: 0.10446739941835403\n",
      "Epoch [1/3], Batch [113], Loss: 0.10481958091259003\n",
      "Epoch [1/3], Batch [114], Loss: 0.10657776892185211\n",
      "Epoch [1/3], Batch [115], Loss: 0.09476940333843231\n",
      "Epoch [1/3], Batch [116], Loss: 0.09872350841760635\n",
      "Epoch [1/3], Batch [117], Loss: 0.11687327921390533\n",
      "Epoch [1/3], Batch [118], Loss: 0.025501269847154617\n",
      "Epoch [1/3], Batch [119], Loss: 0.005402754060924053\n",
      "Epoch [1/3], Batch [120], Loss: 0.005364763550460339\n",
      "Epoch [1/3], Batch [121], Loss: 0.005322971381247044\n",
      "Epoch [1/3], Batch [122], Loss: 0.005277042277157307\n",
      "Epoch [1/3], Batch [123], Loss: 0.005227946676313877\n",
      "Epoch [1/3], Batch [124], Loss: 0.005177012644708157\n",
      "Epoch [1/3], Batch [125], Loss: 0.005120871588587761\n",
      "Epoch [1/3], Batch [126], Loss: 0.026051761582493782\n",
      "Epoch [1/3], Batch [127], Loss: 0.09521188586950302\n",
      "Epoch [1/3], Batch [128], Loss: 0.1077476218342781\n",
      "Epoch [1/3], Batch [129], Loss: 0.09727838635444641\n",
      "Epoch [1/3], Batch [130], Loss: 0.0968441516160965\n",
      "Epoch [1/3], Batch [131], Loss: 0.08315452188253403\n",
      "Epoch [1/3], Batch [132], Loss: 0.0899280309677124\n",
      "Epoch [1/3], Batch [133], Loss: 0.1073605865240097\n",
      "Epoch [1/3], Batch [134], Loss: 0.0889720693230629\n",
      "Epoch [1/3], Batch [135], Loss: 0.004784625023603439\n",
      "Epoch [1/3], Batch [136], Loss: 0.08956890553236008\n",
      "Epoch [1/3], Batch [137], Loss: 0.09827880561351776\n",
      "Epoch [1/3], Batch [138], Loss: 0.11863493919372559\n",
      "Epoch [1/3], Batch [139], Loss: 0.07375622540712357\n",
      "Epoch [1/3], Batch [140], Loss: 0.09329088777303696\n",
      "Epoch [1/3], Batch [141], Loss: 0.0819888710975647\n",
      "Epoch [1/3], Batch [142], Loss: 0.08942063897848129\n",
      "Epoch [1/3], Batch [143], Loss: 0.07900276780128479\n",
      "Epoch [1/3], Batch [144], Loss: 0.11069637537002563\n",
      "Epoch [1/3], Batch [145], Loss: 0.08977488428354263\n",
      "Epoch [1/3], Batch [146], Loss: 0.08385101705789566\n",
      "Epoch [1/3], Batch [147], Loss: 0.10197471082210541\n",
      "Epoch [1/3], Batch [148], Loss: 0.08442028611898422\n",
      "Epoch [1/3], Batch [149], Loss: 0.07427394390106201\n",
      "Epoch [1/3], Batch [150], Loss: 0.0824938416481018\n",
      "Epoch [1/3], Batch [151], Loss: 0.051738809794187546\n",
      "Epoch [1/3], Batch [152], Loss: 0.004529863595962524\n",
      "Epoch [1/3], Batch [153], Loss: 0.004507916979491711\n",
      "Epoch [1/3], Batch [154], Loss: 0.004484664648771286\n",
      "Epoch [1/3], Batch [155], Loss: 0.004454026930034161\n",
      "Epoch [1/3], Batch [156], Loss: 0.004422680474817753\n",
      "Epoch [1/3], Batch [157], Loss: 0.004387598484754562\n",
      "Epoch [1/3], Batch [158], Loss: 0.09395909309387207\n",
      "Epoch [1/3], Batch [159], Loss: 0.10547859966754913\n",
      "Epoch [1/3], Batch [160], Loss: 0.08159174025058746\n",
      "Epoch [1/3], Batch [161], Loss: 0.06812593340873718\n",
      "Epoch [1/3], Batch [162], Loss: 0.0665934756398201\n",
      "Epoch [1/3], Batch [163], Loss: 0.07160551846027374\n",
      "Epoch [1/3], Batch [164], Loss: 0.0791325494647026\n",
      "Epoch [1/3], Batch [165], Loss: 0.06920640170574188\n",
      "Epoch [1/3], Batch [166], Loss: 0.07091180980205536\n",
      "Epoch [1/3], Batch [167], Loss: 0.08230773359537125\n",
      "Epoch [1/3], Batch [168], Loss: 0.028892697766423225\n",
      "Epoch [1/3], Batch [169], Loss: 0.0042014457285404205\n",
      "Epoch [1/3], Batch [170], Loss: 0.004184350371360779\n",
      "Epoch [1/3], Batch [171], Loss: 0.004166444763541222\n",
      "Epoch [1/3], Batch [172], Loss: 0.009331612847745419\n",
      "Epoch [1/3], Batch [173], Loss: 0.06657535582780838\n",
      "Epoch [1/3], Batch [174], Loss: 0.06134899705648422\n",
      "Epoch [1/3], Batch [175], Loss: 0.0574105829000473\n",
      "Epoch [1/3], Batch [176], Loss: 0.07088914513587952\n",
      "Epoch [1/3], Batch [177], Loss: 0.08979218453168869\n",
      "Epoch [1/3], Batch [178], Loss: 0.047511857002973557\n",
      "Epoch [1/3], Batch [179], Loss: 0.05846230685710907\n",
      "Epoch [1/3], Batch [180], Loss: 0.061632461845874786\n",
      "Epoch [1/3], Batch [181], Loss: 0.04853887856006622\n",
      "Epoch [1/3], Batch [182], Loss: 0.06757053732872009\n",
      "Epoch [1/3], Batch [183], Loss: 0.06913173198699951\n",
      "Epoch [1/3], Batch [184], Loss: 0.07134506106376648\n",
      "Epoch [1/3], Batch [185], Loss: 0.022480519488453865\n",
      "Epoch [1/3], Batch [186], Loss: 0.003889405634254217\n",
      "Epoch [1/3], Batch [187], Loss: 0.0038726581260561943\n",
      "Epoch [1/3], Batch [188], Loss: 0.018157383427023888\n",
      "Epoch [1/3], Batch [189], Loss: 0.05167926847934723\n",
      "Epoch [1/3], Batch [190], Loss: 0.05138353258371353\n",
      "Epoch [1/3], Batch [191], Loss: 0.05451957881450653\n",
      "Epoch [1/3], Batch [192], Loss: 0.04962417855858803\n",
      "Epoch [1/3], Batch [193], Loss: 0.06530389189720154\n",
      "Epoch [1/3], Batch [194], Loss: 0.05412331223487854\n",
      "Epoch [1/3], Batch [195], Loss: 0.06404587626457214\n",
      "Epoch [1/3], Batch [196], Loss: 0.054962411522865295\n",
      "Epoch [1/3], Batch [197], Loss: 0.06513063609600067\n",
      "Epoch [1/3], Batch [198], Loss: 0.0548616498708725\n",
      "Epoch [1/3], Batch [199], Loss: 0.05589903146028519\n",
      "Epoch [1/3], Batch [200], Loss: 0.05814571678638458\n",
      "Epoch [1/3], Batch [201], Loss: 0.05653804913163185\n",
      "Epoch [1/3], Batch [202], Loss: 0.0036781528033316135\n",
      "Epoch [1/3], Batch [203], Loss: 0.003666972741484642\n",
      "Epoch [1/3], Batch [204], Loss: 0.0036515281535685062\n",
      "Epoch [1/3], Batch [205], Loss: 0.003632401116192341\n",
      "Epoch [1/3], Batch [206], Loss: 0.0036121057346463203\n",
      "Epoch [1/3], Batch [207], Loss: 0.00359018100425601\n",
      "Epoch [1/3], Batch [208], Loss: 0.004847576841711998\n",
      "Epoch [1/3], Batch [209], Loss: 0.05255437269806862\n",
      "Epoch [1/3], Batch [210], Loss: 0.05867496877908707\n",
      "Epoch [1/3], Batch [211], Loss: 0.0430932380259037\n",
      "Epoch [1/3], Batch [212], Loss: 0.06643331050872803\n",
      "Epoch [1/3], Batch [213], Loss: 0.042076095938682556\n",
      "Epoch [1/3], Batch [214], Loss: 0.05686134099960327\n",
      "Epoch [1/3], Batch [215], Loss: 0.05652838200330734\n",
      "Epoch [1/3], Batch [216], Loss: 0.04150112718343735\n",
      "Epoch [1/3], Batch [217], Loss: 0.0461680069565773\n",
      "Epoch [1/3], Batch [218], Loss: 0.05011903494596481\n",
      "Epoch [1/3], Batch [219], Loss: 0.0034174411557614803\n",
      "Epoch [1/3], Batch [220], Loss: 0.0034053735435009003\n",
      "Epoch [1/3], Batch [221], Loss: 0.0033950181677937508\n",
      "Epoch [1/3], Batch [222], Loss: 0.038998618721961975\n",
      "Epoch [1/3], Batch [223], Loss: 0.04899882897734642\n",
      "Epoch [1/3], Batch [224], Loss: 0.03976310044527054\n",
      "Epoch [1/3], Batch [225], Loss: 0.047014057636260986\n",
      "Epoch [1/3], Batch [226], Loss: 0.048841774463653564\n",
      "Epoch [1/3], Batch [227], Loss: 0.037517547607421875\n",
      "Epoch [1/3], Batch [228], Loss: 0.043814271688461304\n",
      "Epoch [1/3], Batch [229], Loss: 0.056014545261859894\n",
      "Epoch [1/3], Batch [230], Loss: 0.038816407322883606\n",
      "Epoch [1/3], Batch [231], Loss: 0.03348616138100624\n",
      "Epoch [1/3], Batch [232], Loss: 0.043106015771627426\n",
      "Epoch [1/3], Batch [233], Loss: 0.034330036491155624\n",
      "Epoch [1/3], Batch [234], Loss: 0.05092167109251022\n",
      "Epoch [1/3], Batch [235], Loss: 0.01958583854138851\n",
      "Epoch [1/3], Batch [236], Loss: 0.0032204133458435535\n",
      "Epoch [1/3], Batch [237], Loss: 0.0032080095261335373\n",
      "Epoch [1/3], Batch [238], Loss: 0.003191146068274975\n",
      "Epoch [1/3], Batch [239], Loss: 0.003172360360622406\n",
      "Epoch [1/3], Batch [240], Loss: 0.0031536617316305637\n",
      "Epoch [1/3], Batch [241], Loss: 0.0031325332820415497\n",
      "Epoch [1/3], Batch [242], Loss: 0.0031110066920518875\n",
      "Epoch [1/3], Batch [243], Loss: 0.08530937135219574\n",
      "Epoch [1/3], Batch [244], Loss: 0.09272848814725876\n",
      "Epoch [1/3], Batch [245], Loss: 0.09692320972681046\n",
      "Epoch [1/3], Batch [246], Loss: 0.07274390757083893\n",
      "Epoch [1/3], Batch [247], Loss: 0.07113857567310333\n",
      "Epoch [1/3], Batch [248], Loss: 0.08964207023382187\n",
      "Epoch [1/3], Batch [249], Loss: 0.05497033894062042\n",
      "Epoch [1/3], Batch [250], Loss: 0.06047841161489487\n",
      "Epoch [1/3], Batch [251], Loss: 0.08512579649686813\n",
      "Epoch [1/3], Batch [252], Loss: 0.02144571952521801\n",
      "Epoch [1/3], Batch [253], Loss: 0.017510313540697098\n",
      "Epoch [1/3], Batch [254], Loss: 0.04136181250214577\n",
      "Epoch [1/3], Batch [255], Loss: 0.03401452675461769\n",
      "Epoch [1/3], Batch [256], Loss: 0.03181302919983864\n",
      "Epoch [1/3], Batch [257], Loss: 0.030829835683107376\n",
      "Epoch [1/3], Batch [258], Loss: 0.048963651061058044\n",
      "Epoch [1/3], Batch [259], Loss: 0.03434620797634125\n",
      "Epoch [1/3], Batch [260], Loss: 0.03348611667752266\n",
      "Epoch [1/3], Batch [261], Loss: 0.03486704081296921\n",
      "Epoch [1/3], Batch [262], Loss: 0.037339452654123306\n",
      "Epoch [1/3], Batch [263], Loss: 0.023228010162711143\n",
      "Epoch [1/3], Batch [264], Loss: 0.039441972970962524\n",
      "Epoch [1/3], Batch [265], Loss: 0.025796424597501755\n",
      "Epoch [1/3], Batch [266], Loss: 0.028352364897727966\n",
      "Epoch [1/3], Batch [267], Loss: 0.02813570760190487\n",
      "Epoch [1/3], Batch [268], Loss: 0.029872920364141464\n",
      "Epoch [1/3], Batch [269], Loss: 0.0028853625990450382\n",
      "Epoch [1/3], Batch [270], Loss: 0.0028741024434566498\n",
      "Epoch [1/3], Batch [271], Loss: 0.00286397198215127\n",
      "Epoch [1/3], Batch [272], Loss: 0.0028494689613580704\n",
      "Epoch [1/3], Batch [273], Loss: 0.0028327996842563152\n",
      "Epoch [1/3], Batch [274], Loss: 0.002817387692630291\n",
      "Epoch [1/3], Batch [275], Loss: 0.002799482550472021\n",
      "Epoch [1/3], Batch [276], Loss: 0.03449859097599983\n",
      "Epoch [1/3], Batch [277], Loss: 0.03683995455503464\n",
      "Epoch [1/3], Batch [278], Loss: 0.04016201198101044\n",
      "Epoch [1/3], Batch [279], Loss: 0.026156529784202576\n",
      "Epoch [1/3], Batch [280], Loss: 0.03015594370663166\n",
      "Epoch [1/3], Batch [281], Loss: 0.031541794538497925\n",
      "Epoch [1/3], Batch [282], Loss: 0.031713031232357025\n",
      "Epoch [1/3], Batch [283], Loss: 0.025304310023784637\n",
      "Epoch [1/3], Batch [284], Loss: 0.02210458368062973\n",
      "Epoch [1/3], Batch [285], Loss: 0.01916218176484108\n",
      "Epoch [1/3], Batch [286], Loss: 0.0026425952091813087\n",
      "Epoch [1/3], Batch [287], Loss: 0.0026315301656723022\n",
      "Epoch [1/3], Batch [288], Loss: 0.0026186625473201275\n",
      "Epoch [1/3], Batch [289], Loss: 0.0026069520972669125\n",
      "Epoch [1/3], Batch [290], Loss: 0.0025931173004209995\n",
      "Epoch [1/3], Batch [291], Loss: 0.0025787032209336758\n",
      "Epoch [1/3], Batch [292], Loss: 0.011196289211511612\n",
      "Epoch [1/3], Batch [293], Loss: 0.040066130459308624\n",
      "Epoch [1/3], Batch [294], Loss: 0.052836596965789795\n",
      "Epoch [1/3], Batch [295], Loss: 0.03410820662975311\n",
      "Epoch [1/3], Batch [296], Loss: 0.04440572112798691\n",
      "Epoch [1/3], Batch [297], Loss: 0.02351759746670723\n",
      "Epoch [1/3], Batch [298], Loss: 0.036954231560230255\n",
      "Epoch [1/3], Batch [299], Loss: 0.02284572646021843\n",
      "Epoch [1/3], Batch [300], Loss: 0.03588767349720001\n",
      "Epoch [1/3], Batch [301], Loss: 0.026628218591213226\n",
      "Epoch [1/3], Batch [302], Loss: 0.01461060531437397\n",
      "Epoch [1/3], Batch [303], Loss: 0.0024699093773961067\n",
      "Epoch [1/3], Batch [304], Loss: 0.002463811542838812\n",
      "Epoch [1/3], Batch [305], Loss: 0.002454784233123064\n",
      "Epoch [1/3], Batch [306], Loss: 0.002446508966386318\n",
      "Epoch [1/3], Batch [307], Loss: 0.022819610312581062\n",
      "Epoch [1/3], Batch [308], Loss: 0.027861008420586586\n",
      "Epoch [1/3], Batch [309], Loss: 0.033050887286663055\n",
      "Epoch [1/3], Batch [310], Loss: 0.020864037796854973\n",
      "Epoch [1/3], Batch [311], Loss: 0.02868645265698433\n",
      "Epoch [1/3], Batch [312], Loss: 0.024367839097976685\n",
      "Epoch [1/3], Batch [313], Loss: 0.02298629842698574\n",
      "Epoch [1/3], Batch [314], Loss: 0.023138578981161118\n",
      "Epoch [1/3], Batch [315], Loss: 0.021298848092556\n",
      "Epoch [1/3], Batch [316], Loss: 0.0203364547342062\n",
      "Epoch [1/3], Batch [317], Loss: 0.021107126027345657\n",
      "Epoch [1/3], Batch [318], Loss: 0.027546025812625885\n",
      "Epoch [1/3], Batch [319], Loss: 0.006801297422498465\n",
      "Epoch [1/3], Batch [320], Loss: 0.002335416153073311\n",
      "Epoch [1/3], Batch [321], Loss: 0.0023290454410016537\n",
      "Epoch [1/3], Batch [322], Loss: 0.0023205243051052094\n",
      "Epoch [1/3], Batch [323], Loss: 0.0023115379735827446\n",
      "Epoch [1/3], Batch [324], Loss: 0.002301360946148634\n",
      "Epoch [1/3], Batch [325], Loss: 0.0022904123179614544\n",
      "Epoch [1/3], Batch [326], Loss: 0.002279168926179409\n",
      "Epoch [1/3], Batch [327], Loss: 0.002267989795655012\n",
      "Epoch [1/3], Batch [328], Loss: 0.002255052328109741\n",
      "Epoch [1/3], Batch [329], Loss: 0.07197532057762146\n",
      "Epoch [1/3], Batch [330], Loss: 0.1430991142988205\n",
      "Epoch [1/3], Batch [331], Loss: 0.02734135277569294\n",
      "Epoch [1/3], Batch [332], Loss: 0.07868003100156784\n",
      "Epoch [1/3], Batch [333], Loss: 0.035531964153051376\n",
      "Epoch [1/3], Batch [334], Loss: 0.044339559972286224\n",
      "Epoch [1/3], Batch [335], Loss: 0.082661472260952\n",
      "Epoch [1/3], Batch [336], Loss: 0.06554187834262848\n",
      "Epoch [1/3], Batch [337], Loss: 0.08620927482843399\n",
      "Epoch [1/3], Batch [338], Loss: 0.06043495982885361\n",
      "Epoch [1/3], Batch [339], Loss: 0.03596876561641693\n",
      "Epoch [1/3], Batch [340], Loss: 0.06500649452209473\n",
      "Epoch [1/3], Batch [341], Loss: 0.06133522838354111\n",
      "Epoch [1/3], Batch [342], Loss: 0.06884398311376572\n",
      "Epoch [1/3], Batch [343], Loss: 0.03962411731481552\n",
      "Epoch [1/3], Batch [344], Loss: 0.07063020020723343\n",
      "Epoch [1/3], Batch [345], Loss: 0.06408144533634186\n",
      "Epoch [1/3], Batch [346], Loss: 0.045547064393758774\n",
      "Epoch [1/3], Batch [347], Loss: 0.05107296630740166\n",
      "Epoch [1/3], Batch [348], Loss: 0.039471592754125595\n",
      "Epoch [1/3], Batch [349], Loss: 0.04372991994023323\n",
      "Epoch [1/3], Batch [350], Loss: 0.06516557931900024\n",
      "Epoch [1/3], Batch [351], Loss: 0.06822732090950012\n",
      "Epoch [1/3], Batch [352], Loss: 0.027252057567238808\n",
      "Epoch [1/3], Batch [353], Loss: 0.0022048582322895527\n",
      "Epoch [1/3], Batch [354], Loss: 0.00220309616997838\n",
      "Epoch [1/3], Batch [355], Loss: 0.002200208604335785\n",
      "Epoch [1/3], Batch [356], Loss: 0.002196061424911022\n",
      "Epoch [1/3], Batch [357], Loss: 0.0065488810651004314\n",
      "Epoch [1/3], Batch [358], Loss: 0.017598174512386322\n",
      "Epoch [1/3], Batch [359], Loss: 0.02215433493256569\n",
      "Epoch [1/3], Batch [360], Loss: 0.02234404720366001\n",
      "Epoch [1/3], Batch [361], Loss: 0.022836286574602127\n",
      "Epoch [1/3], Batch [362], Loss: 0.019173983484506607\n",
      "Epoch [1/3], Batch [363], Loss: 0.019883153960108757\n",
      "Epoch [1/3], Batch [364], Loss: 0.015567271038889885\n",
      "Epoch [1/3], Batch [365], Loss: 0.01908394880592823\n",
      "Epoch [1/3], Batch [366], Loss: 0.024875998497009277\n",
      "Epoch [1/3], Batch [367], Loss: 0.019698133692145348\n",
      "Epoch [1/3], Batch [368], Loss: 0.019455567002296448\n",
      "Epoch [1/3], Batch [369], Loss: 0.0093302633613348\n",
      "Epoch [1/3], Batch [370], Loss: 0.0020713566336780787\n",
      "Epoch [1/3], Batch [371], Loss: 0.02084426023066044\n",
      "Epoch [1/3], Batch [372], Loss: 0.02112695574760437\n",
      "Epoch [1/3], Batch [373], Loss: 0.021758398041129112\n",
      "Epoch [1/3], Batch [374], Loss: 0.01696140319108963\n",
      "Epoch [1/3], Batch [375], Loss: 0.02142598293721676\n",
      "Epoch [1/3], Batch [376], Loss: 0.015561733394861221\n",
      "Epoch [1/3], Batch [377], Loss: 0.025764260441064835\n",
      "Epoch [1/3], Batch [378], Loss: 0.026018578559160233\n",
      "Epoch [1/3], Batch [379], Loss: 0.013299875892698765\n",
      "Epoch [1/3], Batch [380], Loss: 0.02785564213991165\n",
      "Epoch [1/3], Batch [381], Loss: 0.019625049084424973\n",
      "Epoch [1/3], Batch [382], Loss: 0.01946718618273735\n",
      "Epoch [1/3], Batch [383], Loss: 0.01677900366485119\n",
      "Epoch [1/3], Batch [384], Loss: 0.014755887910723686\n",
      "Epoch [1/3], Batch [385], Loss: 0.014515068382024765\n",
      "Epoch [1/3], Batch [386], Loss: 0.013953356072306633\n",
      "Epoch [2/3], Batch [1], Loss: 0.002017493359744549\n",
      "Epoch [2/3], Batch [2], Loss: 0.002010590862482786\n",
      "Epoch [2/3], Batch [3], Loss: 0.03579038381576538\n",
      "Epoch [2/3], Batch [4], Loss: 0.022247465327382088\n",
      "Epoch [2/3], Batch [5], Loss: 0.04483969882130623\n",
      "Epoch [2/3], Batch [6], Loss: 0.018697045743465424\n",
      "Epoch [2/3], Batch [7], Loss: 0.02716078609228134\n",
      "Epoch [2/3], Batch [8], Loss: 0.027638742700219154\n",
      "Epoch [2/3], Batch [9], Loss: 0.02528751641511917\n",
      "Epoch [2/3], Batch [10], Loss: 0.03961379453539848\n",
      "Epoch [2/3], Batch [11], Loss: 0.02661088854074478\n",
      "Epoch [2/3], Batch [12], Loss: 0.02267463132739067\n",
      "Epoch [2/3], Batch [13], Loss: 0.024491136893630028\n",
      "Epoch [2/3], Batch [14], Loss: 0.0269430261105299\n",
      "Epoch [2/3], Batch [15], Loss: 0.02397555485367775\n",
      "Epoch [2/3], Batch [16], Loss: 0.032321684062480927\n",
      "Epoch [2/3], Batch [17], Loss: 0.015897519886493683\n",
      "Epoch [2/3], Batch [18], Loss: 0.0019294193480163813\n",
      "Epoch [2/3], Batch [19], Loss: 0.0019237352535128593\n",
      "Epoch [2/3], Batch [20], Loss: 0.0019177887588739395\n",
      "Epoch [2/3], Batch [21], Loss: 0.0019109789282083511\n",
      "Epoch [2/3], Batch [22], Loss: 0.008009172976016998\n",
      "Epoch [2/3], Batch [23], Loss: 0.011478797532618046\n",
      "Epoch [2/3], Batch [24], Loss: 0.013192715123295784\n",
      "Epoch [2/3], Batch [25], Loss: 0.019004909321665764\n",
      "Epoch [2/3], Batch [26], Loss: 0.011788550764322281\n",
      "Epoch [2/3], Batch [27], Loss: 0.014058071188628674\n",
      "Epoch [2/3], Batch [28], Loss: 0.014045940712094307\n",
      "Epoch [2/3], Batch [29], Loss: 0.012565995566546917\n",
      "Epoch [2/3], Batch [30], Loss: 0.012564631178975105\n",
      "Epoch [2/3], Batch [31], Loss: 0.014009768143296242\n",
      "Epoch [2/3], Batch [32], Loss: 0.011345185339450836\n",
      "Epoch [2/3], Batch [33], Loss: 0.010438511148095131\n",
      "Epoch [2/3], Batch [34], Loss: 0.00645839236676693\n",
      "Epoch [2/3], Batch [35], Loss: 0.001848319312557578\n",
      "Epoch [2/3], Batch [36], Loss: 0.01143964659422636\n",
      "Epoch [2/3], Batch [37], Loss: 0.012185921892523766\n",
      "Epoch [2/3], Batch [38], Loss: 0.02090330608189106\n",
      "Epoch [2/3], Batch [39], Loss: 0.012602193281054497\n",
      "Epoch [2/3], Batch [40], Loss: 0.018760163336992264\n",
      "Epoch [2/3], Batch [41], Loss: 0.012721499428153038\n",
      "Epoch [2/3], Batch [42], Loss: 0.009736532345414162\n",
      "Epoch [2/3], Batch [43], Loss: 0.012130985036492348\n",
      "Epoch [2/3], Batch [44], Loss: 0.018257003277540207\n",
      "Epoch [2/3], Batch [45], Loss: 0.015427075326442719\n",
      "Epoch [2/3], Batch [46], Loss: 0.012378395535051823\n",
      "Epoch [2/3], Batch [47], Loss: 0.015569332987070084\n",
      "Epoch [2/3], Batch [48], Loss: 0.013054262846708298\n",
      "Epoch [2/3], Batch [49], Loss: 0.013923914171755314\n",
      "Epoch [2/3], Batch [50], Loss: 0.010655011981725693\n",
      "Epoch [2/3], Batch [51], Loss: 0.003868703730404377\n",
      "Epoch [2/3], Batch [52], Loss: 0.01349061168730259\n",
      "Epoch [2/3], Batch [53], Loss: 0.02060968428850174\n",
      "Epoch [2/3], Batch [54], Loss: 0.01539994589984417\n",
      "Epoch [2/3], Batch [55], Loss: 0.020647918805480003\n",
      "Epoch [2/3], Batch [56], Loss: 0.019555851817131042\n",
      "Epoch [2/3], Batch [57], Loss: 0.014142096042633057\n",
      "Epoch [2/3], Batch [58], Loss: 0.01818333938717842\n",
      "Epoch [2/3], Batch [59], Loss: 0.03252905234694481\n",
      "Epoch [2/3], Batch [60], Loss: 0.013730165548622608\n",
      "Epoch [2/3], Batch [61], Loss: 0.010751357302069664\n",
      "Epoch [2/3], Batch [62], Loss: 0.016164366155862808\n",
      "Epoch [2/3], Batch [63], Loss: 0.019960975274443626\n",
      "Epoch [2/3], Batch [64], Loss: 0.015213990584015846\n",
      "Epoch [2/3], Batch [65], Loss: 0.02159666270017624\n",
      "Epoch [2/3], Batch [66], Loss: 0.019309580326080322\n",
      "Epoch [2/3], Batch [67], Loss: 0.020651094615459442\n",
      "Epoch [2/3], Batch [68], Loss: 0.001732941484078765\n",
      "Epoch [2/3], Batch [69], Loss: 0.0017292313277721405\n",
      "Epoch [2/3], Batch [70], Loss: 0.0017255288548767567\n",
      "Epoch [2/3], Batch [71], Loss: 0.0017199201975017786\n",
      "Epoch [2/3], Batch [72], Loss: 0.0017131839413195848\n",
      "Epoch [2/3], Batch [73], Loss: 0.0017052185721695423\n",
      "Epoch [2/3], Batch [74], Loss: 0.008224990218877792\n",
      "Epoch [2/3], Batch [75], Loss: 0.015993550419807434\n",
      "Epoch [2/3], Batch [76], Loss: 0.012906113639473915\n",
      "Epoch [2/3], Batch [77], Loss: 0.011227935552597046\n",
      "Epoch [2/3], Batch [78], Loss: 0.01338237151503563\n",
      "Epoch [2/3], Batch [79], Loss: 0.010624055750668049\n",
      "Epoch [2/3], Batch [80], Loss: 0.010300153866410255\n",
      "Epoch [2/3], Batch [81], Loss: 0.01678263396024704\n",
      "Epoch [2/3], Batch [82], Loss: 0.008866662159562111\n",
      "Epoch [2/3], Batch [83], Loss: 0.01765383966267109\n",
      "Epoch [2/3], Batch [84], Loss: 0.009980740956962109\n",
      "Epoch [2/3], Batch [85], Loss: 0.0016368953511118889\n",
      "Epoch [2/3], Batch [86], Loss: 0.001633174018934369\n",
      "Epoch [2/3], Batch [87], Loss: 0.0016279453411698341\n",
      "Epoch [2/3], Batch [88], Loss: 0.0016222044359892607\n",
      "Epoch [2/3], Batch [89], Loss: 0.003853772534057498\n",
      "Epoch [2/3], Batch [90], Loss: 0.019289519637823105\n",
      "Epoch [2/3], Batch [91], Loss: 0.013464327901601791\n",
      "Epoch [2/3], Batch [92], Loss: 0.011268364265561104\n",
      "Epoch [2/3], Batch [93], Loss: 0.02300863340497017\n",
      "Epoch [2/3], Batch [94], Loss: 0.016254279762506485\n",
      "Epoch [2/3], Batch [95], Loss: 0.01924731209874153\n",
      "Epoch [2/3], Batch [96], Loss: 0.027094392105937004\n",
      "Epoch [2/3], Batch [97], Loss: 0.020634550601243973\n",
      "Epoch [2/3], Batch [98], Loss: 0.01442441251128912\n",
      "Epoch [2/3], Batch [99], Loss: 0.009871171787381172\n",
      "Epoch [2/3], Batch [100], Loss: 0.019026145339012146\n",
      "Epoch [2/3], Batch [101], Loss: 0.004859827924519777\n",
      "Epoch [2/3], Batch [102], Loss: 0.0015727374702692032\n",
      "Epoch [2/3], Batch [103], Loss: 0.0015697162598371506\n",
      "Epoch [2/3], Batch [104], Loss: 0.0015656466130167246\n",
      "Epoch [2/3], Batch [105], Loss: 0.008723551407456398\n",
      "Epoch [2/3], Batch [106], Loss: 0.010767564177513123\n",
      "Epoch [2/3], Batch [107], Loss: 0.01794813759624958\n",
      "Epoch [2/3], Batch [108], Loss: 0.013601420447230339\n",
      "Epoch [2/3], Batch [109], Loss: 0.015561232343316078\n",
      "Epoch [2/3], Batch [110], Loss: 0.013149724341928959\n",
      "Epoch [2/3], Batch [111], Loss: 0.011868011206388474\n",
      "Epoch [2/3], Batch [112], Loss: 0.009346400387585163\n",
      "Epoch [2/3], Batch [113], Loss: 0.009629753418266773\n",
      "Epoch [2/3], Batch [114], Loss: 0.011807069182395935\n",
      "Epoch [2/3], Batch [115], Loss: 0.00910661555826664\n",
      "Epoch [2/3], Batch [116], Loss: 0.010234908200800419\n",
      "Epoch [2/3], Batch [117], Loss: 0.011707635596394539\n",
      "Epoch [2/3], Batch [118], Loss: 0.005131816025823355\n",
      "Epoch [2/3], Batch [119], Loss: 0.0015087730716913939\n",
      "Epoch [2/3], Batch [120], Loss: 0.00150462263263762\n",
      "Epoch [2/3], Batch [121], Loss: 0.0015003618318587542\n",
      "Epoch [2/3], Batch [122], Loss: 0.0014958574902266264\n",
      "Epoch [2/3], Batch [123], Loss: 0.0014898539520800114\n",
      "Epoch [2/3], Batch [124], Loss: 0.0014833256136626005\n",
      "Epoch [2/3], Batch [125], Loss: 0.0014770668931305408\n",
      "Epoch [2/3], Batch [126], Loss: 0.0028570450376719236\n",
      "Epoch [2/3], Batch [127], Loss: 0.00914616510272026\n",
      "Epoch [2/3], Batch [128], Loss: 0.009321309626102448\n",
      "Epoch [2/3], Batch [129], Loss: 0.00869770534336567\n",
      "Epoch [2/3], Batch [130], Loss: 0.010103531181812286\n",
      "Epoch [2/3], Batch [131], Loss: 0.007463742978870869\n",
      "Epoch [2/3], Batch [132], Loss: 0.007858005352318287\n",
      "Epoch [2/3], Batch [133], Loss: 0.00846823863685131\n",
      "Epoch [2/3], Batch [134], Loss: 0.007346969097852707\n",
      "Epoch [2/3], Batch [135], Loss: 0.0014232166577130556\n",
      "Epoch [2/3], Batch [136], Loss: 0.011415529064834118\n",
      "Epoch [2/3], Batch [137], Loss: 0.008129021152853966\n",
      "Epoch [2/3], Batch [138], Loss: 0.016456391662359238\n",
      "Epoch [2/3], Batch [139], Loss: 0.007259210105985403\n",
      "Epoch [2/3], Batch [140], Loss: 0.008950581774115562\n",
      "Epoch [2/3], Batch [141], Loss: 0.007507425267249346\n",
      "Epoch [2/3], Batch [142], Loss: 0.008580085821449757\n",
      "Epoch [2/3], Batch [143], Loss: 0.010862510651350021\n",
      "Epoch [2/3], Batch [144], Loss: 0.015523732639849186\n",
      "Epoch [2/3], Batch [145], Loss: 0.010056816041469574\n",
      "Epoch [2/3], Batch [146], Loss: 0.008641927503049374\n",
      "Epoch [2/3], Batch [147], Loss: 0.014308116398751736\n",
      "Epoch [2/3], Batch [148], Loss: 0.010576716624200344\n",
      "Epoch [2/3], Batch [149], Loss: 0.007364506833255291\n",
      "Epoch [2/3], Batch [150], Loss: 0.008326169103384018\n",
      "Epoch [2/3], Batch [151], Loss: 0.007699847221374512\n",
      "Epoch [2/3], Batch [152], Loss: 0.0013782007154077291\n",
      "Epoch [2/3], Batch [153], Loss: 0.0013759152498096228\n",
      "Epoch [2/3], Batch [154], Loss: 0.0013725317548960447\n",
      "Epoch [2/3], Batch [155], Loss: 0.0013688737526535988\n",
      "Epoch [2/3], Batch [156], Loss: 0.0013645270373672247\n",
      "Epoch [2/3], Batch [157], Loss: 0.0013600995298475027\n",
      "Epoch [2/3], Batch [158], Loss: 0.017221441492438316\n",
      "Epoch [2/3], Batch [159], Loss: 0.023048147559165955\n",
      "Epoch [2/3], Batch [160], Loss: 0.014486236497759819\n",
      "Epoch [2/3], Batch [161], Loss: 0.008317966014146805\n",
      "Epoch [2/3], Batch [162], Loss: 0.008099017664790154\n",
      "Epoch [2/3], Batch [163], Loss: 0.00797843188047409\n",
      "Epoch [2/3], Batch [164], Loss: 0.01486897375434637\n",
      "Epoch [2/3], Batch [165], Loss: 0.014082130044698715\n",
      "Epoch [2/3], Batch [166], Loss: 0.01433755736798048\n",
      "Epoch [2/3], Batch [167], Loss: 0.014433518052101135\n",
      "Epoch [2/3], Batch [168], Loss: 0.005532729439437389\n",
      "Epoch [2/3], Batch [169], Loss: 0.0013266850728541613\n",
      "Epoch [2/3], Batch [170], Loss: 0.0013246405869722366\n",
      "Epoch [2/3], Batch [171], Loss: 0.0013220785185694695\n",
      "Epoch [2/3], Batch [172], Loss: 0.0018952125683426857\n",
      "Epoch [2/3], Batch [173], Loss: 0.008029437623918056\n",
      "Epoch [2/3], Batch [174], Loss: 0.007768833078444004\n",
      "Epoch [2/3], Batch [175], Loss: 0.01091716904193163\n",
      "Epoch [2/3], Batch [176], Loss: 0.011652493849396706\n",
      "Epoch [2/3], Batch [177], Loss: 0.01958627440035343\n",
      "Epoch [2/3], Batch [178], Loss: 0.009517279453575611\n",
      "Epoch [2/3], Batch [179], Loss: 0.008884931914508343\n",
      "Epoch [2/3], Batch [180], Loss: 0.010086923837661743\n",
      "Epoch [2/3], Batch [181], Loss: 0.00962723046541214\n",
      "Epoch [2/3], Batch [182], Loss: 0.008738059550523758\n",
      "Epoch [2/3], Batch [183], Loss: 0.012350465171039104\n",
      "Epoch [2/3], Batch [184], Loss: 0.008398212492465973\n",
      "Epoch [2/3], Batch [185], Loss: 0.003006506245583296\n",
      "Epoch [2/3], Batch [186], Loss: 0.0012759265955537558\n",
      "Epoch [2/3], Batch [187], Loss: 0.0012717372737824917\n",
      "Epoch [2/3], Batch [188], Loss: 0.0029606714379042387\n",
      "Epoch [2/3], Batch [189], Loss: 0.0076675377786159515\n",
      "Epoch [2/3], Batch [190], Loss: 0.010808083228766918\n",
      "Epoch [2/3], Batch [191], Loss: 0.00769257266074419\n",
      "Epoch [2/3], Batch [192], Loss: 0.007235963828861713\n",
      "Epoch [2/3], Batch [193], Loss: 0.012199101969599724\n",
      "Epoch [2/3], Batch [194], Loss: 0.007207377348095179\n",
      "Epoch [2/3], Batch [195], Loss: 0.009909785352647305\n",
      "Epoch [2/3], Batch [196], Loss: 0.008459036238491535\n",
      "Epoch [2/3], Batch [197], Loss: 0.010843081399798393\n",
      "Epoch [2/3], Batch [198], Loss: 0.00792935211211443\n",
      "Epoch [2/3], Batch [199], Loss: 0.009287501685321331\n",
      "Epoch [2/3], Batch [200], Loss: 0.011361939832568169\n",
      "Epoch [2/3], Batch [201], Loss: 0.009296469390392303\n",
      "Epoch [2/3], Batch [202], Loss: 0.0012356671504676342\n",
      "Epoch [2/3], Batch [203], Loss: 0.001234026625752449\n",
      "Epoch [2/3], Batch [204], Loss: 0.0012316391803324223\n",
      "Epoch [2/3], Batch [205], Loss: 0.001228333916515112\n",
      "Epoch [2/3], Batch [206], Loss: 0.001225420506671071\n",
      "Epoch [2/3], Batch [207], Loss: 0.0012217811308801174\n",
      "Epoch [2/3], Batch [208], Loss: 0.0014178215060383081\n",
      "Epoch [2/3], Batch [209], Loss: 0.010451428592205048\n",
      "Epoch [2/3], Batch [210], Loss: 0.011759363114833832\n",
      "Epoch [2/3], Batch [211], Loss: 0.008404184132814407\n",
      "Epoch [2/3], Batch [212], Loss: 0.015794944018125534\n",
      "Epoch [2/3], Batch [213], Loss: 0.007226794026792049\n",
      "Epoch [2/3], Batch [214], Loss: 0.012553609907627106\n",
      "Epoch [2/3], Batch [215], Loss: 0.013021501712501049\n",
      "Epoch [2/3], Batch [216], Loss: 0.008303898386657238\n",
      "Epoch [2/3], Batch [217], Loss: 0.008571704849600792\n",
      "Epoch [2/3], Batch [218], Loss: 0.013306494802236557\n",
      "Epoch [2/3], Batch [219], Loss: 0.0011875322088599205\n",
      "Epoch [2/3], Batch [220], Loss: 0.0011850823648273945\n",
      "Epoch [2/3], Batch [221], Loss: 0.001183115877211094\n",
      "Epoch [2/3], Batch [222], Loss: 0.006719237193465233\n",
      "Epoch [2/3], Batch [223], Loss: 0.009035009890794754\n",
      "Epoch [2/3], Batch [224], Loss: 0.00678523164242506\n",
      "Epoch [2/3], Batch [225], Loss: 0.009348629973828793\n",
      "Epoch [2/3], Batch [226], Loss: 0.008549360558390617\n",
      "Epoch [2/3], Batch [227], Loss: 0.006812604609876871\n",
      "Epoch [2/3], Batch [228], Loss: 0.009357056580483913\n",
      "Epoch [2/3], Batch [229], Loss: 0.012087813578546047\n",
      "Epoch [2/3], Batch [230], Loss: 0.007267185021191835\n",
      "Epoch [2/3], Batch [231], Loss: 0.006494496017694473\n",
      "Epoch [2/3], Batch [232], Loss: 0.008449459448456764\n",
      "Epoch [2/3], Batch [233], Loss: 0.007688382640480995\n",
      "Epoch [2/3], Batch [234], Loss: 0.014276605099439621\n",
      "Epoch [2/3], Batch [235], Loss: 0.003576564369723201\n",
      "Epoch [2/3], Batch [236], Loss: 0.001149453455582261\n",
      "Epoch [2/3], Batch [237], Loss: 0.0011472527403384447\n",
      "Epoch [2/3], Batch [238], Loss: 0.001144694397225976\n",
      "Epoch [2/3], Batch [239], Loss: 0.001141235465183854\n",
      "Epoch [2/3], Batch [240], Loss: 0.0011378792114555836\n",
      "Epoch [2/3], Batch [241], Loss: 0.0011343257501721382\n",
      "Epoch [2/3], Batch [242], Loss: 0.0011314398143440485\n",
      "Epoch [2/3], Batch [243], Loss: 0.011066358536481857\n",
      "Epoch [2/3], Batch [244], Loss: 0.010502704419195652\n",
      "Epoch [2/3], Batch [245], Loss: 0.011115482077002525\n",
      "Epoch [2/3], Batch [246], Loss: 0.009219721890985966\n",
      "Epoch [2/3], Batch [247], Loss: 0.00875039678066969\n",
      "Epoch [2/3], Batch [248], Loss: 0.013397164642810822\n",
      "Epoch [2/3], Batch [249], Loss: 0.0071814339607954025\n",
      "Epoch [2/3], Batch [250], Loss: 0.009538255631923676\n",
      "Epoch [2/3], Batch [251], Loss: 0.010959676466882229\n",
      "Epoch [2/3], Batch [252], Loss: 0.003358454443514347\n",
      "Epoch [2/3], Batch [253], Loss: 0.0034357821568846703\n",
      "Epoch [2/3], Batch [254], Loss: 0.011504238471388817\n",
      "Epoch [2/3], Batch [255], Loss: 0.007821157574653625\n",
      "Epoch [2/3], Batch [256], Loss: 0.005897773429751396\n",
      "Epoch [2/3], Batch [257], Loss: 0.0061136167496442795\n",
      "Epoch [2/3], Batch [258], Loss: 0.010417180135846138\n",
      "Epoch [2/3], Batch [259], Loss: 0.0076872240751981735\n",
      "Epoch [2/3], Batch [260], Loss: 0.006620870903134346\n",
      "Epoch [2/3], Batch [261], Loss: 0.007582375314086676\n",
      "Epoch [2/3], Batch [262], Loss: 0.00879872776567936\n",
      "Epoch [2/3], Batch [263], Loss: 0.004997622221708298\n",
      "Epoch [2/3], Batch [264], Loss: 0.010817022062838078\n",
      "Epoch [2/3], Batch [265], Loss: 0.005333228502422571\n",
      "Epoch [2/3], Batch [266], Loss: 0.005776489619165659\n",
      "Epoch [2/3], Batch [267], Loss: 0.006153248716145754\n",
      "Epoch [2/3], Batch [268], Loss: 0.006570769473910332\n",
      "Epoch [2/3], Batch [269], Loss: 0.0010718530975282192\n",
      "Epoch [2/3], Batch [270], Loss: 0.0010702493600547314\n",
      "Epoch [2/3], Batch [271], Loss: 0.0010673732031136751\n",
      "Epoch [2/3], Batch [272], Loss: 0.0010653033386915922\n",
      "Epoch [2/3], Batch [273], Loss: 0.001062591327354312\n",
      "Epoch [2/3], Batch [274], Loss: 0.001059151254594326\n",
      "Epoch [2/3], Batch [275], Loss: 0.0010563181713223457\n",
      "Epoch [2/3], Batch [276], Loss: 0.012693086639046669\n",
      "Epoch [2/3], Batch [277], Loss: 0.009016242809593678\n",
      "Epoch [2/3], Batch [278], Loss: 0.01082893367856741\n",
      "Epoch [2/3], Batch [279], Loss: 0.005986111704260111\n",
      "Epoch [2/3], Batch [280], Loss: 0.007667757570743561\n",
      "Epoch [2/3], Batch [281], Loss: 0.005977192893624306\n",
      "Epoch [2/3], Batch [282], Loss: 0.007605928461998701\n",
      "Epoch [2/3], Batch [283], Loss: 0.006367268972098827\n",
      "Epoch [2/3], Batch [284], Loss: 0.005646064877510071\n",
      "Epoch [2/3], Batch [285], Loss: 0.004728544503450394\n",
      "Epoch [2/3], Batch [286], Loss: 0.0010287899058312178\n",
      "Epoch [2/3], Batch [287], Loss: 0.0010264527518302202\n",
      "Epoch [2/3], Batch [288], Loss: 0.001024162513203919\n",
      "Epoch [2/3], Batch [289], Loss: 0.0010215345537289977\n",
      "Epoch [2/3], Batch [290], Loss: 0.0010189395397901535\n",
      "Epoch [2/3], Batch [291], Loss: 0.0010158728109672666\n",
      "Epoch [2/3], Batch [292], Loss: 0.002797376597300172\n",
      "Epoch [2/3], Batch [293], Loss: 0.011661617085337639\n",
      "Epoch [2/3], Batch [294], Loss: 0.014053170569241047\n",
      "Epoch [2/3], Batch [295], Loss: 0.008637207560241222\n",
      "Epoch [2/3], Batch [296], Loss: 0.011263225227594376\n",
      "Epoch [2/3], Batch [297], Loss: 0.005729584023356438\n",
      "Epoch [2/3], Batch [298], Loss: 0.010984683409333229\n",
      "Epoch [2/3], Batch [299], Loss: 0.00521961972117424\n",
      "Epoch [2/3], Batch [300], Loss: 0.009491509757936\n",
      "Epoch [2/3], Batch [301], Loss: 0.006300702691078186\n",
      "Epoch [2/3], Batch [302], Loss: 0.003392888931557536\n",
      "Epoch [2/3], Batch [303], Loss: 0.0009900470031425357\n",
      "Epoch [2/3], Batch [304], Loss: 0.0009886084590107203\n",
      "Epoch [2/3], Batch [305], Loss: 0.0009861403377726674\n",
      "Epoch [2/3], Batch [306], Loss: 0.0009837105171754956\n",
      "Epoch [2/3], Batch [307], Loss: 0.005385122261941433\n",
      "Epoch [2/3], Batch [308], Loss: 0.009286402724683285\n",
      "Epoch [2/3], Batch [309], Loss: 0.00962329376488924\n",
      "Epoch [2/3], Batch [310], Loss: 0.005630659405142069\n",
      "Epoch [2/3], Batch [311], Loss: 0.007669713348150253\n",
      "Epoch [2/3], Batch [312], Loss: 0.006757470313459635\n",
      "Epoch [2/3], Batch [313], Loss: 0.005500808358192444\n",
      "Epoch [2/3], Batch [314], Loss: 0.005812785588204861\n",
      "Epoch [2/3], Batch [315], Loss: 0.005927513353526592\n",
      "Epoch [2/3], Batch [316], Loss: 0.004917595535516739\n",
      "Epoch [2/3], Batch [317], Loss: 0.00521691283211112\n",
      "Epoch [2/3], Batch [318], Loss: 0.007179242558777332\n",
      "Epoch [2/3], Batch [319], Loss: 0.0019872449338436127\n",
      "Epoch [2/3], Batch [320], Loss: 0.000958322430960834\n",
      "Epoch [2/3], Batch [321], Loss: 0.0009563550120219588\n",
      "Epoch [2/3], Batch [322], Loss: 0.0009538425365462899\n",
      "Epoch [2/3], Batch [323], Loss: 0.0009524223860353231\n",
      "Epoch [2/3], Batch [324], Loss: 0.0009502765024080873\n",
      "Epoch [2/3], Batch [325], Loss: 0.0009478391148149967\n",
      "Epoch [2/3], Batch [326], Loss: 0.0009451856603845954\n",
      "Epoch [2/3], Batch [327], Loss: 0.000942669459618628\n",
      "Epoch [2/3], Batch [328], Loss: 0.0009392044739797711\n",
      "Epoch [2/3], Batch [329], Loss: 0.008349703624844551\n",
      "Epoch [2/3], Batch [330], Loss: 0.01989069953560829\n",
      "Epoch [2/3], Batch [331], Loss: 0.007187712471932173\n",
      "Epoch [2/3], Batch [332], Loss: 0.012874629348516464\n",
      "Epoch [2/3], Batch [333], Loss: 0.008195588365197182\n",
      "Epoch [2/3], Batch [334], Loss: 0.008495970629155636\n",
      "Epoch [2/3], Batch [335], Loss: 0.015656163915991783\n",
      "Epoch [2/3], Batch [336], Loss: 0.014749613590538502\n",
      "Epoch [2/3], Batch [337], Loss: 0.018778599798679352\n",
      "Epoch [2/3], Batch [338], Loss: 0.013495342805981636\n",
      "Epoch [2/3], Batch [339], Loss: 0.009146873839199543\n",
      "Epoch [2/3], Batch [340], Loss: 0.012495988979935646\n",
      "Epoch [2/3], Batch [341], Loss: 0.016675012186169624\n",
      "Epoch [2/3], Batch [342], Loss: 0.0130063621327281\n",
      "Epoch [2/3], Batch [343], Loss: 0.009425772354006767\n",
      "Epoch [2/3], Batch [344], Loss: 0.01596522331237793\n",
      "Epoch [2/3], Batch [345], Loss: 0.015871744602918625\n",
      "Epoch [2/3], Batch [346], Loss: 0.012723692692816257\n",
      "Epoch [2/3], Batch [347], Loss: 0.012796859256923199\n",
      "Epoch [2/3], Batch [348], Loss: 0.011320967227220535\n",
      "Epoch [2/3], Batch [349], Loss: 0.01475025899708271\n",
      "Epoch [2/3], Batch [350], Loss: 0.01587708294391632\n",
      "Epoch [2/3], Batch [351], Loss: 0.017217159271240234\n",
      "Epoch [2/3], Batch [352], Loss: 0.0076475804671645164\n",
      "Epoch [2/3], Batch [353], Loss: 0.0009024281753227115\n",
      "Epoch [2/3], Batch [354], Loss: 0.000901738996617496\n",
      "Epoch [2/3], Batch [355], Loss: 0.0009003279265016317\n",
      "Epoch [2/3], Batch [356], Loss: 0.0008992231450974941\n",
      "Epoch [2/3], Batch [357], Loss: 0.0018213785951957107\n",
      "Epoch [2/3], Batch [358], Loss: 0.004789006896317005\n",
      "Epoch [2/3], Batch [359], Loss: 0.006856163032352924\n",
      "Epoch [2/3], Batch [360], Loss: 0.006349347531795502\n",
      "Epoch [2/3], Batch [361], Loss: 0.00635729031637311\n",
      "Epoch [2/3], Batch [362], Loss: 0.005440468899905682\n",
      "Epoch [2/3], Batch [363], Loss: 0.0053811222314834595\n",
      "Epoch [2/3], Batch [364], Loss: 0.004489055369049311\n",
      "Epoch [2/3], Batch [365], Loss: 0.005370703525841236\n",
      "Epoch [2/3], Batch [366], Loss: 0.008866856805980206\n",
      "Epoch [2/3], Batch [367], Loss: 0.005577370524406433\n",
      "Epoch [2/3], Batch [368], Loss: 0.005424472503364086\n",
      "Epoch [2/3], Batch [369], Loss: 0.0030348333530128\n",
      "Epoch [2/3], Batch [370], Loss: 0.0008764686062932014\n",
      "Epoch [2/3], Batch [371], Loss: 0.006562495604157448\n",
      "Epoch [2/3], Batch [372], Loss: 0.006853420287370682\n",
      "Epoch [2/3], Batch [373], Loss: 0.006449677050113678\n",
      "Epoch [2/3], Batch [374], Loss: 0.005357187241315842\n",
      "Epoch [2/3], Batch [375], Loss: 0.006046181544661522\n",
      "Epoch [2/3], Batch [376], Loss: 0.00457020103931427\n",
      "Epoch [2/3], Batch [377], Loss: 0.008685659617185593\n",
      "Epoch [2/3], Batch [378], Loss: 0.008844725787639618\n",
      "Epoch [2/3], Batch [379], Loss: 0.004170630127191544\n",
      "Epoch [2/3], Batch [380], Loss: 0.009796777740120888\n",
      "Epoch [2/3], Batch [381], Loss: 0.008685464039444923\n",
      "Epoch [2/3], Batch [382], Loss: 0.006284525617957115\n",
      "Epoch [2/3], Batch [383], Loss: 0.005221977364271879\n",
      "Epoch [2/3], Batch [384], Loss: 0.004597917664796114\n",
      "Epoch [2/3], Batch [385], Loss: 0.004732005298137665\n",
      "Epoch [2/3], Batch [386], Loss: 0.004367153160274029\n",
      "Epoch [3/3], Batch [1], Loss: 0.0008612241363152862\n",
      "Epoch [3/3], Batch [2], Loss: 0.0008603547466918826\n",
      "Epoch [3/3], Batch [3], Loss: 0.010681509040296078\n",
      "Epoch [3/3], Batch [4], Loss: 0.007676578126847744\n",
      "Epoch [3/3], Batch [5], Loss: 0.015240354463458061\n",
      "Epoch [3/3], Batch [6], Loss: 0.006846778094768524\n",
      "Epoch [3/3], Batch [7], Loss: 0.008024798706173897\n",
      "Epoch [3/3], Batch [8], Loss: 0.008704893290996552\n",
      "Epoch [3/3], Batch [9], Loss: 0.007990105077624321\n",
      "Epoch [3/3], Batch [10], Loss: 0.01379617303609848\n",
      "Epoch [3/3], Batch [11], Loss: 0.00923163816332817\n",
      "Epoch [3/3], Batch [12], Loss: 0.008140779100358486\n",
      "Epoch [3/3], Batch [13], Loss: 0.008692532777786255\n",
      "Epoch [3/3], Batch [14], Loss: 0.008823261596262455\n",
      "Epoch [3/3], Batch [15], Loss: 0.007668314501643181\n",
      "Epoch [3/3], Batch [16], Loss: 0.011113508604466915\n",
      "Epoch [3/3], Batch [17], Loss: 0.0052049304358661175\n",
      "Epoch [3/3], Batch [18], Loss: 0.0008409692673012614\n",
      "Epoch [3/3], Batch [19], Loss: 0.0008400854421779513\n",
      "Epoch [3/3], Batch [20], Loss: 0.0008388309506699443\n",
      "Epoch [3/3], Batch [21], Loss: 0.0008371673757210374\n",
      "Epoch [3/3], Batch [22], Loss: 0.003035385860130191\n",
      "Epoch [3/3], Batch [23], Loss: 0.003978820517659187\n",
      "Epoch [3/3], Batch [24], Loss: 0.004314282909035683\n",
      "Epoch [3/3], Batch [25], Loss: 0.006270393263548613\n",
      "Epoch [3/3], Batch [26], Loss: 0.0040220776572823524\n",
      "Epoch [3/3], Batch [27], Loss: 0.004576337523758411\n",
      "Epoch [3/3], Batch [28], Loss: 0.004700121004134417\n",
      "Epoch [3/3], Batch [29], Loss: 0.0041992515325546265\n",
      "Epoch [3/3], Batch [30], Loss: 0.00421797065064311\n",
      "Epoch [3/3], Batch [31], Loss: 0.005711361300200224\n",
      "Epoch [3/3], Batch [32], Loss: 0.003988780081272125\n",
      "Epoch [3/3], Batch [33], Loss: 0.0037548926193267107\n",
      "Epoch [3/3], Batch [34], Loss: 0.0024074832908809185\n",
      "Epoch [3/3], Batch [35], Loss: 0.0008264575153589249\n",
      "Epoch [3/3], Batch [36], Loss: 0.006281958892941475\n",
      "Epoch [3/3], Batch [37], Loss: 0.004185229539871216\n",
      "Epoch [3/3], Batch [38], Loss: 0.007678366266191006\n",
      "Epoch [3/3], Batch [39], Loss: 0.004306402988731861\n",
      "Epoch [3/3], Batch [40], Loss: 0.006886803545057774\n",
      "Epoch [3/3], Batch [41], Loss: 0.004446974024176598\n",
      "Epoch [3/3], Batch [42], Loss: 0.003621171461418271\n",
      "Epoch [3/3], Batch [43], Loss: 0.004272086545825005\n",
      "Epoch [3/3], Batch [44], Loss: 0.007248338777571917\n",
      "Epoch [3/3], Batch [45], Loss: 0.005379918962717056\n",
      "Epoch [3/3], Batch [46], Loss: 0.004391046240925789\n",
      "Epoch [3/3], Batch [47], Loss: 0.005427788011729717\n",
      "Epoch [3/3], Batch [48], Loss: 0.00448780320584774\n",
      "Epoch [3/3], Batch [49], Loss: 0.005067821592092514\n",
      "Epoch [3/3], Batch [50], Loss: 0.00397413270547986\n",
      "Epoch [3/3], Batch [51], Loss: 0.0015523640904575586\n",
      "Epoch [3/3], Batch [52], Loss: 0.005105399992316961\n",
      "Epoch [3/3], Batch [53], Loss: 0.006957013159990311\n",
      "Epoch [3/3], Batch [54], Loss: 0.005035755690187216\n",
      "Epoch [3/3], Batch [55], Loss: 0.006466373801231384\n",
      "Epoch [3/3], Batch [56], Loss: 0.006581237073987722\n",
      "Epoch [3/3], Batch [57], Loss: 0.004822614602744579\n",
      "Epoch [3/3], Batch [58], Loss: 0.006325721275061369\n",
      "Epoch [3/3], Batch [59], Loss: 0.011898365803062916\n",
      "Epoch [3/3], Batch [60], Loss: 0.005004056729376316\n",
      "Epoch [3/3], Batch [61], Loss: 0.003990035504102707\n",
      "Epoch [3/3], Batch [62], Loss: 0.00621638260781765\n",
      "Epoch [3/3], Batch [63], Loss: 0.008094250224530697\n",
      "Epoch [3/3], Batch [64], Loss: 0.0055028642527759075\n",
      "Epoch [3/3], Batch [65], Loss: 0.00795330572873354\n",
      "Epoch [3/3], Batch [66], Loss: 0.006952700205147266\n",
      "Epoch [3/3], Batch [67], Loss: 0.007749574258923531\n",
      "Epoch [3/3], Batch [68], Loss: 0.0007974505424499512\n",
      "Epoch [3/3], Batch [69], Loss: 0.0007963282987475395\n",
      "Epoch [3/3], Batch [70], Loss: 0.0007949128048494458\n",
      "Epoch [3/3], Batch [71], Loss: 0.0007933919550850987\n",
      "Epoch [3/3], Batch [72], Loss: 0.0007917215116322041\n",
      "Epoch [3/3], Batch [73], Loss: 0.000789515906944871\n",
      "Epoch [3/3], Batch [74], Loss: 0.0032738959416747093\n",
      "Epoch [3/3], Batch [75], Loss: 0.006376613862812519\n",
      "Epoch [3/3], Batch [76], Loss: 0.005101919174194336\n",
      "Epoch [3/3], Batch [77], Loss: 0.004002097994089127\n",
      "Epoch [3/3], Batch [78], Loss: 0.005598735064268112\n",
      "Epoch [3/3], Batch [79], Loss: 0.0038817953318357468\n",
      "Epoch [3/3], Batch [80], Loss: 0.0039962162263691425\n",
      "Epoch [3/3], Batch [81], Loss: 0.006053426302969456\n",
      "Epoch [3/3], Batch [82], Loss: 0.003439913969486952\n",
      "Epoch [3/3], Batch [83], Loss: 0.008070197887718678\n",
      "Epoch [3/3], Batch [84], Loss: 0.005426192656159401\n",
      "Epoch [3/3], Batch [85], Loss: 0.0007706810720264912\n",
      "Epoch [3/3], Batch [86], Loss: 0.0007690229685977101\n",
      "Epoch [3/3], Batch [87], Loss: 0.0007675971137359738\n",
      "Epoch [3/3], Batch [88], Loss: 0.0007659656694158912\n",
      "Epoch [3/3], Batch [89], Loss: 0.0013577999779954553\n",
      "Epoch [3/3], Batch [90], Loss: 0.007666509132832289\n",
      "Epoch [3/3], Batch [91], Loss: 0.004726343788206577\n",
      "Epoch [3/3], Batch [92], Loss: 0.00432635098695755\n",
      "Epoch [3/3], Batch [93], Loss: 0.009039128199219704\n",
      "Epoch [3/3], Batch [94], Loss: 0.005956767126917839\n",
      "Epoch [3/3], Batch [95], Loss: 0.008287155069410801\n",
      "Epoch [3/3], Batch [96], Loss: 0.010353483259677887\n",
      "Epoch [3/3], Batch [97], Loss: 0.0089936638250947\n",
      "Epoch [3/3], Batch [98], Loss: 0.0053310818038880825\n",
      "Epoch [3/3], Batch [99], Loss: 0.0038484050892293453\n",
      "Epoch [3/3], Batch [100], Loss: 0.007371245417743921\n",
      "Epoch [3/3], Batch [101], Loss: 0.002069523325189948\n",
      "Epoch [3/3], Batch [102], Loss: 0.0007473222212865949\n",
      "Epoch [3/3], Batch [103], Loss: 0.0007461208151653409\n",
      "Epoch [3/3], Batch [104], Loss: 0.0007452549180015922\n",
      "Epoch [3/3], Batch [105], Loss: 0.0034420208539813757\n",
      "Epoch [3/3], Batch [106], Loss: 0.0039682649075984955\n",
      "Epoch [3/3], Batch [107], Loss: 0.00805642455816269\n",
      "Epoch [3/3], Batch [108], Loss: 0.005796248093247414\n",
      "Epoch [3/3], Batch [109], Loss: 0.007514043245464563\n",
      "Epoch [3/3], Batch [110], Loss: 0.005421042442321777\n",
      "Epoch [3/3], Batch [111], Loss: 0.006119543686509132\n",
      "Epoch [3/3], Batch [112], Loss: 0.004187113605439663\n",
      "Epoch [3/3], Batch [113], Loss: 0.004416223615407944\n",
      "Epoch [3/3], Batch [114], Loss: 0.005015286151319742\n",
      "Epoch [3/3], Batch [115], Loss: 0.0038296713028103113\n",
      "Epoch [3/3], Batch [116], Loss: 0.004283935762941837\n",
      "Epoch [3/3], Batch [117], Loss: 0.0043058451265096664\n",
      "Epoch [3/3], Batch [118], Loss: 0.001997933257371187\n",
      "Epoch [3/3], Batch [119], Loss: 0.0007290689973160625\n",
      "Epoch [3/3], Batch [120], Loss: 0.0007276741089299321\n",
      "Epoch [3/3], Batch [121], Loss: 0.0007263838779181242\n",
      "Epoch [3/3], Batch [122], Loss: 0.0007249250775203109\n",
      "Epoch [3/3], Batch [123], Loss: 0.0007232121424749494\n",
      "Epoch [3/3], Batch [124], Loss: 0.0007212389027699828\n",
      "Epoch [3/3], Batch [125], Loss: 0.0007191606564447284\n",
      "Epoch [3/3], Batch [126], Loss: 0.001290922169573605\n",
      "Epoch [3/3], Batch [127], Loss: 0.0036848525051027536\n",
      "Epoch [3/3], Batch [128], Loss: 0.0037365304306149483\n",
      "Epoch [3/3], Batch [129], Loss: 0.003513602539896965\n",
      "Epoch [3/3], Batch [130], Loss: 0.003857910167425871\n",
      "Epoch [3/3], Batch [131], Loss: 0.003183850320056081\n",
      "Epoch [3/3], Batch [132], Loss: 0.0033440226688981056\n",
      "Epoch [3/3], Batch [133], Loss: 0.0035384870134294033\n",
      "Epoch [3/3], Batch [134], Loss: 0.0031982907094061375\n",
      "Epoch [3/3], Batch [135], Loss: 0.0007026445819064975\n",
      "Epoch [3/3], Batch [136], Loss: 0.004657507408410311\n",
      "Epoch [3/3], Batch [137], Loss: 0.0034431624226272106\n",
      "Epoch [3/3], Batch [138], Loss: 0.008393555879592896\n",
      "Epoch [3/3], Batch [139], Loss: 0.003126970725134015\n",
      "Epoch [3/3], Batch [140], Loss: 0.0036533712409436703\n",
      "Epoch [3/3], Batch [141], Loss: 0.0032540191896259785\n",
      "Epoch [3/3], Batch [142], Loss: 0.00349147105589509\n",
      "Epoch [3/3], Batch [143], Loss: 0.005018237978219986\n",
      "Epoch [3/3], Batch [144], Loss: 0.005838229786604643\n",
      "Epoch [3/3], Batch [145], Loss: 0.004187533166259527\n",
      "Epoch [3/3], Batch [146], Loss: 0.0034891969989985228\n",
      "Epoch [3/3], Batch [147], Loss: 0.006187183316797018\n",
      "Epoch [3/3], Batch [148], Loss: 0.004876549355685711\n",
      "Epoch [3/3], Batch [149], Loss: 0.0032129534520208836\n",
      "Epoch [3/3], Batch [150], Loss: 0.0034995409660041332\n",
      "Epoch [3/3], Batch [151], Loss: 0.0033561084419488907\n",
      "Epoch [3/3], Batch [152], Loss: 0.0006882156012579799\n",
      "Epoch [3/3], Batch [153], Loss: 0.0006875400431454182\n",
      "Epoch [3/3], Batch [154], Loss: 0.0006865530740469694\n",
      "Epoch [3/3], Batch [155], Loss: 0.0006849066121503711\n",
      "Epoch [3/3], Batch [156], Loss: 0.0006836854154244065\n",
      "Epoch [3/3], Batch [157], Loss: 0.0006821647984907031\n",
      "Epoch [3/3], Batch [158], Loss: 0.008578089997172356\n",
      "Epoch [3/3], Batch [159], Loss: 0.009319470264017582\n",
      "Epoch [3/3], Batch [160], Loss: 0.00569711672142148\n",
      "Epoch [3/3], Batch [161], Loss: 0.003376957029104233\n",
      "Epoch [3/3], Batch [162], Loss: 0.003390213707461953\n",
      "Epoch [3/3], Batch [163], Loss: 0.003371915780007839\n",
      "Epoch [3/3], Batch [164], Loss: 0.005154760088771582\n",
      "Epoch [3/3], Batch [165], Loss: 0.0061587016098201275\n",
      "Epoch [3/3], Batch [166], Loss: 0.006837669759988785\n",
      "Epoch [3/3], Batch [167], Loss: 0.006293440703302622\n",
      "Epoch [3/3], Batch [168], Loss: 0.0026072408072650433\n",
      "Epoch [3/3], Batch [169], Loss: 0.0006708097644150257\n",
      "Epoch [3/3], Batch [170], Loss: 0.0006700855446979403\n",
      "Epoch [3/3], Batch [171], Loss: 0.000669076107442379\n",
      "Epoch [3/3], Batch [172], Loss: 0.0009036606643348932\n",
      "Epoch [3/3], Batch [173], Loss: 0.003493879921734333\n",
      "Epoch [3/3], Batch [174], Loss: 0.0033898595720529556\n",
      "Epoch [3/3], Batch [175], Loss: 0.006451970897614956\n",
      "Epoch [3/3], Batch [176], Loss: 0.004730796441435814\n",
      "Epoch [3/3], Batch [177], Loss: 0.007024596445262432\n",
      "Epoch [3/3], Batch [178], Loss: 0.0057608927600085735\n",
      "Epoch [3/3], Batch [179], Loss: 0.003601508215069771\n",
      "Epoch [3/3], Batch [180], Loss: 0.004379425663501024\n",
      "Epoch [3/3], Batch [181], Loss: 0.004841864109039307\n",
      "Epoch [3/3], Batch [182], Loss: 0.003712414763867855\n",
      "Epoch [3/3], Batch [183], Loss: 0.005121233407407999\n",
      "Epoch [3/3], Batch [184], Loss: 0.0036630902905017138\n",
      "Epoch [3/3], Batch [185], Loss: 0.0013921234058216214\n",
      "Epoch [3/3], Batch [186], Loss: 0.000652695307508111\n",
      "Epoch [3/3], Batch [187], Loss: 0.0006514447741210461\n",
      "Epoch [3/3], Batch [188], Loss: 0.0013987901620566845\n",
      "Epoch [3/3], Batch [189], Loss: 0.003438615007326007\n",
      "Epoch [3/3], Batch [190], Loss: 0.0062018693424761295\n",
      "Epoch [3/3], Batch [191], Loss: 0.003274203510954976\n",
      "Epoch [3/3], Batch [192], Loss: 0.003220852231606841\n",
      "Epoch [3/3], Batch [193], Loss: 0.004863582085818052\n",
      "Epoch [3/3], Batch [194], Loss: 0.0032150233164429665\n",
      "Epoch [3/3], Batch [195], Loss: 0.0043010413646698\n",
      "Epoch [3/3], Batch [196], Loss: 0.004558505490422249\n",
      "Epoch [3/3], Batch [197], Loss: 0.0058381212875247\n",
      "Epoch [3/3], Batch [198], Loss: 0.003514450043439865\n",
      "Epoch [3/3], Batch [199], Loss: 0.0038032045122236013\n",
      "Epoch [3/3], Batch [200], Loss: 0.005053799599409103\n",
      "Epoch [3/3], Batch [201], Loss: 0.004267093725502491\n",
      "Epoch [3/3], Batch [202], Loss: 0.0006374542135745287\n",
      "Epoch [3/3], Batch [203], Loss: 0.0006364058936014771\n",
      "Epoch [3/3], Batch [204], Loss: 0.0006356387166306376\n",
      "Epoch [3/3], Batch [205], Loss: 0.0006345125148072839\n",
      "Epoch [3/3], Batch [206], Loss: 0.0006334639620035887\n",
      "Epoch [3/3], Batch [207], Loss: 0.0006321470718830824\n",
      "Epoch [3/3], Batch [208], Loss: 0.0007227956084534526\n",
      "Epoch [3/3], Batch [209], Loss: 0.004819155670702457\n",
      "Epoch [3/3], Batch [210], Loss: 0.004904547706246376\n",
      "Epoch [3/3], Batch [211], Loss: 0.003589276224374771\n",
      "Epoch [3/3], Batch [212], Loss: 0.008138015866279602\n",
      "Epoch [3/3], Batch [213], Loss: 0.003710855497047305\n",
      "Epoch [3/3], Batch [214], Loss: 0.005350807216018438\n",
      "Epoch [3/3], Batch [215], Loss: 0.006109895650297403\n",
      "Epoch [3/3], Batch [216], Loss: 0.003649321384727955\n",
      "Epoch [3/3], Batch [217], Loss: 0.003657547291368246\n",
      "Epoch [3/3], Batch [218], Loss: 0.00489125307649374\n",
      "Epoch [3/3], Batch [219], Loss: 0.0006193106528371572\n",
      "Epoch [3/3], Batch [220], Loss: 0.000618351623415947\n",
      "Epoch [3/3], Batch [221], Loss: 0.0006175014423206449\n",
      "Epoch [3/3], Batch [222], Loss: 0.002806375501677394\n",
      "Epoch [3/3], Batch [223], Loss: 0.003846285864710808\n",
      "Epoch [3/3], Batch [224], Loss: 0.003020145930349827\n",
      "Epoch [3/3], Batch [225], Loss: 0.004003794863820076\n",
      "Epoch [3/3], Batch [226], Loss: 0.0036740624345839024\n",
      "Epoch [3/3], Batch [227], Loss: 0.003054569009691477\n",
      "Epoch [3/3], Batch [228], Loss: 0.00420455913990736\n",
      "Epoch [3/3], Batch [229], Loss: 0.004845954477787018\n",
      "Epoch [3/3], Batch [230], Loss: 0.0031677584629505873\n",
      "Epoch [3/3], Batch [231], Loss: 0.0029621156863868237\n",
      "Epoch [3/3], Batch [232], Loss: 0.003631395287811756\n",
      "Epoch [3/3], Batch [233], Loss: 0.0034750676713883877\n",
      "Epoch [3/3], Batch [234], Loss: 0.00653291679918766\n",
      "Epoch [3/3], Batch [235], Loss: 0.001733391429297626\n",
      "Epoch [3/3], Batch [236], Loss: 0.0006043926114216447\n",
      "Epoch [3/3], Batch [237], Loss: 0.0006035427795723081\n",
      "Epoch [3/3], Batch [238], Loss: 0.000602307147346437\n",
      "Epoch [3/3], Batch [239], Loss: 0.0006013390375301242\n",
      "Epoch [3/3], Batch [240], Loss: 0.0006000769790261984\n",
      "Epoch [3/3], Batch [241], Loss: 0.0005990441422909498\n",
      "Epoch [3/3], Batch [242], Loss: 0.000597521779127419\n",
      "Epoch [3/3], Batch [243], Loss: 0.005044407211244106\n",
      "Epoch [3/3], Batch [244], Loss: 0.00466875871643424\n",
      "Epoch [3/3], Batch [245], Loss: 0.004847399890422821\n",
      "Epoch [3/3], Batch [246], Loss: 0.003975765313953161\n",
      "Epoch [3/3], Batch [247], Loss: 0.0038363286294043064\n",
      "Epoch [3/3], Batch [248], Loss: 0.005683352239429951\n",
      "Epoch [3/3], Batch [249], Loss: 0.0033143905457109213\n",
      "Epoch [3/3], Batch [250], Loss: 0.004361665807664394\n",
      "Epoch [3/3], Batch [251], Loss: 0.004892547614872456\n",
      "Epoch [3/3], Batch [252], Loss: 0.0015613435534760356\n",
      "Epoch [3/3], Batch [253], Loss: 0.001593540539033711\n",
      "Epoch [3/3], Batch [254], Loss: 0.004859818145632744\n",
      "Epoch [3/3], Batch [255], Loss: 0.003515752498060465\n",
      "Epoch [3/3], Batch [256], Loss: 0.0027558566071093082\n",
      "Epoch [3/3], Batch [257], Loss: 0.002921439940109849\n",
      "Epoch [3/3], Batch [258], Loss: 0.004259261768311262\n",
      "Epoch [3/3], Batch [259], Loss: 0.003681349800899625\n",
      "Epoch [3/3], Batch [260], Loss: 0.0029219125863164663\n",
      "Epoch [3/3], Batch [261], Loss: 0.003274738322943449\n",
      "Epoch [3/3], Batch [262], Loss: 0.0038358550518751144\n",
      "Epoch [3/3], Batch [263], Loss: 0.002461584284901619\n",
      "Epoch [3/3], Batch [264], Loss: 0.004323895089328289\n",
      "Epoch [3/3], Batch [265], Loss: 0.002604276640340686\n",
      "Epoch [3/3], Batch [266], Loss: 0.0027697058394551277\n",
      "Epoch [3/3], Batch [267], Loss: 0.0028476365841925144\n",
      "Epoch [3/3], Batch [268], Loss: 0.0029640442226082087\n",
      "Epoch [3/3], Batch [269], Loss: 0.0005753084551542997\n",
      "Epoch [3/3], Batch [270], Loss: 0.0005745142698287964\n",
      "Epoch [3/3], Batch [271], Loss: 0.0005735071608796716\n",
      "Epoch [3/3], Batch [272], Loss: 0.0005726178642362356\n",
      "Epoch [3/3], Batch [273], Loss: 0.0005714826984331012\n",
      "Epoch [3/3], Batch [274], Loss: 0.0005704843206331134\n",
      "Epoch [3/3], Batch [275], Loss: 0.0005690682446584105\n",
      "Epoch [3/3], Batch [276], Loss: 0.004766950383782387\n",
      "Epoch [3/3], Batch [277], Loss: 0.003939846530556679\n",
      "Epoch [3/3], Batch [278], Loss: 0.005635321605950594\n",
      "Epoch [3/3], Batch [279], Loss: 0.0027708597481250763\n",
      "Epoch [3/3], Batch [280], Loss: 0.004046871792525053\n",
      "Epoch [3/3], Batch [281], Loss: 0.002834760583937168\n",
      "Epoch [3/3], Batch [282], Loss: 0.0034099523909389973\n",
      "Epoch [3/3], Batch [283], Loss: 0.002913104370236397\n",
      "Epoch [3/3], Batch [284], Loss: 0.0026589531917124987\n",
      "Epoch [3/3], Batch [285], Loss: 0.002220981754362583\n",
      "Epoch [3/3], Batch [286], Loss: 0.0005582186859101057\n",
      "Epoch [3/3], Batch [287], Loss: 0.0005574141396209598\n",
      "Epoch [3/3], Batch [288], Loss: 0.0005560291465371847\n",
      "Epoch [3/3], Batch [289], Loss: 0.000555105390958488\n",
      "Epoch [3/3], Batch [290], Loss: 0.0005539511330425739\n",
      "Epoch [3/3], Batch [291], Loss: 0.0005529535701498389\n",
      "Epoch [3/3], Batch [292], Loss: 0.0013906657695770264\n",
      "Epoch [3/3], Batch [293], Loss: 0.005495291668921709\n",
      "Epoch [3/3], Batch [294], Loss: 0.005805519409477711\n",
      "Epoch [3/3], Batch [295], Loss: 0.004083355888724327\n",
      "Epoch [3/3], Batch [296], Loss: 0.004712832625955343\n",
      "Epoch [3/3], Batch [297], Loss: 0.0026443391107022762\n",
      "Epoch [3/3], Batch [298], Loss: 0.004699441604316235\n",
      "Epoch [3/3], Batch [299], Loss: 0.002542979083955288\n",
      "Epoch [3/3], Batch [300], Loss: 0.00392419658601284\n",
      "Epoch [3/3], Batch [301], Loss: 0.0028746617026627064\n",
      "Epoch [3/3], Batch [302], Loss: 0.0016834648558869958\n",
      "Epoch [3/3], Batch [303], Loss: 0.0005413235630840063\n",
      "Epoch [3/3], Batch [304], Loss: 0.0005406778072938323\n",
      "Epoch [3/3], Batch [305], Loss: 0.0005397293716669083\n",
      "Epoch [3/3], Batch [306], Loss: 0.000538802589289844\n",
      "Epoch [3/3], Batch [307], Loss: 0.0024760067462921143\n",
      "Epoch [3/3], Batch [308], Loss: 0.004099948797374964\n",
      "Epoch [3/3], Batch [309], Loss: 0.0038793024141341448\n",
      "Epoch [3/3], Batch [310], Loss: 0.0026484839618206024\n",
      "Epoch [3/3], Batch [311], Loss: 0.0034035667777061462\n",
      "Epoch [3/3], Batch [312], Loss: 0.0033692806027829647\n",
      "Epoch [3/3], Batch [313], Loss: 0.0026526751462370157\n",
      "Epoch [3/3], Batch [314], Loss: 0.0026632193475961685\n",
      "Epoch [3/3], Batch [315], Loss: 0.0027541927993297577\n",
      "Epoch [3/3], Batch [316], Loss: 0.002458775881677866\n",
      "Epoch [3/3], Batch [317], Loss: 0.0026085879653692245\n",
      "Epoch [3/3], Batch [318], Loss: 0.003169167321175337\n",
      "Epoch [3/3], Batch [319], Loss: 0.0010273884981870651\n",
      "Epoch [3/3], Batch [320], Loss: 0.0005280300974845886\n",
      "Epoch [3/3], Batch [321], Loss: 0.000527295982465148\n",
      "Epoch [3/3], Batch [322], Loss: 0.0005267317174002528\n",
      "Epoch [3/3], Batch [323], Loss: 0.0005258794408291578\n",
      "Epoch [3/3], Batch [324], Loss: 0.0005250404356047511\n",
      "Epoch [3/3], Batch [325], Loss: 0.0005238426383584738\n",
      "Epoch [3/3], Batch [326], Loss: 0.0005227325018495321\n",
      "Epoch [3/3], Batch [327], Loss: 0.0005214923294261098\n",
      "Epoch [3/3], Batch [328], Loss: 0.00052034598775208\n",
      "Epoch [3/3], Batch [329], Loss: 0.0037944000214338303\n",
      "Epoch [3/3], Batch [330], Loss: 0.009539579972624779\n",
      "Epoch [3/3], Batch [331], Loss: 0.0031499797478318214\n",
      "Epoch [3/3], Batch [332], Loss: 0.00553375668823719\n",
      "Epoch [3/3], Batch [333], Loss: 0.00438980758190155\n",
      "Epoch [3/3], Batch [334], Loss: 0.004015201702713966\n",
      "Epoch [3/3], Batch [335], Loss: 0.006588347256183624\n",
      "Epoch [3/3], Batch [336], Loss: 0.006164072081446648\n",
      "Epoch [3/3], Batch [337], Loss: 0.008815702050924301\n",
      "Epoch [3/3], Batch [338], Loss: 0.006086078006774187\n",
      "Epoch [3/3], Batch [339], Loss: 0.004168094135820866\n",
      "Epoch [3/3], Batch [340], Loss: 0.005572677589952946\n",
      "Epoch [3/3], Batch [341], Loss: 0.007104428485035896\n",
      "Epoch [3/3], Batch [342], Loss: 0.006205662153661251\n",
      "Epoch [3/3], Batch [343], Loss: 0.005010995082557201\n",
      "Epoch [3/3], Batch [344], Loss: 0.007022164296358824\n",
      "Epoch [3/3], Batch [345], Loss: 0.007399370428174734\n",
      "Epoch [3/3], Batch [346], Loss: 0.006625854875892401\n",
      "Epoch [3/3], Batch [347], Loss: 0.005821160972118378\n",
      "Epoch [3/3], Batch [348], Loss: 0.005095713771879673\n",
      "Epoch [3/3], Batch [349], Loss: 0.00905198697000742\n",
      "Epoch [3/3], Batch [350], Loss: 0.007234709337353706\n",
      "Epoch [3/3], Batch [351], Loss: 0.007579514756798744\n",
      "Epoch [3/3], Batch [352], Loss: 0.0034944929648190737\n",
      "Epoch [3/3], Batch [353], Loss: 0.0005039979005232453\n",
      "Epoch [3/3], Batch [354], Loss: 0.0005034668720327318\n",
      "Epoch [3/3], Batch [355], Loss: 0.0005031177424825728\n",
      "Epoch [3/3], Batch [356], Loss: 0.0005024865386076272\n",
      "Epoch [3/3], Batch [357], Loss: 0.000939083518460393\n",
      "Epoch [3/3], Batch [358], Loss: 0.002429040614515543\n",
      "Epoch [3/3], Batch [359], Loss: 0.003935538232326508\n",
      "Epoch [3/3], Batch [360], Loss: 0.0029587573371827602\n",
      "Epoch [3/3], Batch [361], Loss: 0.0029960519168525934\n",
      "Epoch [3/3], Batch [362], Loss: 0.002669081324711442\n",
      "Epoch [3/3], Batch [363], Loss: 0.0025891009718179703\n",
      "Epoch [3/3], Batch [364], Loss: 0.0023092986084520817\n",
      "Epoch [3/3], Batch [365], Loss: 0.00261603482067585\n",
      "Epoch [3/3], Batch [366], Loss: 0.004257530905306339\n",
      "Epoch [3/3], Batch [367], Loss: 0.002745219739153981\n",
      "Epoch [3/3], Batch [368], Loss: 0.0026836206670850515\n",
      "Epoch [3/3], Batch [369], Loss: 0.0015320677775889635\n",
      "Epoch [3/3], Batch [370], Loss: 0.0004930957220494747\n",
      "Epoch [3/3], Batch [371], Loss: 0.00283437455072999\n",
      "Epoch [3/3], Batch [372], Loss: 0.0030929166823625565\n",
      "Epoch [3/3], Batch [373], Loss: 0.0030891771893948317\n",
      "Epoch [3/3], Batch [374], Loss: 0.0026675076223909855\n",
      "Epoch [3/3], Batch [375], Loss: 0.002898628357797861\n",
      "Epoch [3/3], Batch [376], Loss: 0.002382510108873248\n",
      "Epoch [3/3], Batch [377], Loss: 0.003764822380617261\n",
      "Epoch [3/3], Batch [378], Loss: 0.004427380859851837\n",
      "Epoch [3/3], Batch [379], Loss: 0.0022019052412360907\n",
      "Epoch [3/3], Batch [380], Loss: 0.004469098523259163\n",
      "Epoch [3/3], Batch [381], Loss: 0.005923967342823744\n",
      "Epoch [3/3], Batch [382], Loss: 0.002866168273612857\n",
      "Epoch [3/3], Batch [383], Loss: 0.0024743694812059402\n",
      "Epoch [3/3], Batch [384], Loss: 0.002392380964010954\n",
      "Epoch [3/3], Batch [385], Loss: 0.0024064418394118547\n",
      "Epoch [3/3], Batch [386], Loss: 0.0022847908549010754\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import gc\n",
    "\n",
    "model.train()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 3\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (a, b) in enumerate(zip(s, o)):\n",
    "        a = a.to(device)\n",
    "        b = b.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            logits = model(a, b)\n",
    "            loss = lossFn(logits.view(-1, model.vocab_size), b.view(-1).long())\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}], Loss: {loss.item()}\")\n",
    "\n",
    "        # Log the loss\n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch * len(inputs) + i)\n",
    "    \n",
    "        a = a.cpu()\n",
    "        b = b.cpu()\n",
    "        logits = logits.cpu()\n",
    "        loss = loss.cpu()\n",
    "        del a, b, logits, loss\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Close the SummaryWriter\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd369a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:56:40.125724Z",
     "iopub.status.busy": "2024-07-18T01:56:40.124991Z",
     "iopub.status.idle": "2024-07-18T01:56:50.844642Z",
     "shell.execute_reply": "2024-07-18T01:56:50.843836Z"
    },
    "papermill": {
     "duration": 10.81694,
     "end_time": "2024-07-18T01:56:50.846798",
     "exception": false,
     "start_time": "2024-07-18T01:56:40.029858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = torch.randint(low=0, high=85, size=(16, 256), dtype=torch.long, device=device)\n",
    "a = model.generate(context, max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f66b9d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:56:51.039746Z",
     "iopub.status.busy": "2024-07-18T01:56:51.039420Z",
     "iopub.status.idle": "2024-07-18T01:56:51.055707Z",
     "shell.execute_reply": "2024-07-18T01:56:51.054827Z"
    },
    "papermill": {
     "duration": 0.114417,
     "end_time": "2024-07-18T01:56:51.057575",
     "exception": false,
     "start_time": "2024-07-18T01:56:50.943158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDoooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooommmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%ddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOORRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRRPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPPP'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.to(\"cpu\")\n",
    "q = \"\"\n",
    "for i in a:\n",
    "    for j in i:\n",
    "        q += detok[int(j)]\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817244d",
   "metadata": {
    "papermill": {
     "duration": 0.094928,
     "end_time": "2024-07-18T01:56:51.247872",
     "exception": false,
     "start_time": "2024-07-18T01:56:51.152944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 683366,
     "sourceId": 1199344,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 404.294898,
   "end_time": "2024-07-18T01:56:54.214011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-18T01:50:09.919113",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
